# RF-DETR-FSCD: Few-Shot Counting and Detection

## <a name="Weights"></a>æƒé‡æ–‡ä»¶ (Weights)
ğŸ’¡ Note: ç®—åŠ›é™åˆ¶å½“å‰æä¾›çš„æƒé‡ä»…è®­ç»ƒäº† 10 ä¸ª Epochã€‚éšç€è®­ç»ƒè½®æ•°çš„å¢åŠ ï¼Œæ¨¡å‹æ€§èƒ½æœ‰æœ›è¿›ä¸€æ­¥æå‡ã€‚
é€šè¿‡ç½‘ç›˜åˆ†äº«çš„æ–‡ä»¶ï¼šcheckpoint0009.pth
é“¾æ¥: https://pan.baidu.com/s/1qjRXuc6sIl0WlkLGKzSyiA?pwd=wfei æå–ç : wfei


## <a name="visual-results"></a>ğŸ–¼ï¸ å¯è§†åŒ–å±•ç¤º (Visual Results)

ä»…éœ€ **1 ä¸ªç¤ºä¾‹æ¡† (Single Exemplar Box)**ï¼Œæ¨¡å‹å³å¯åœ¨æå°‘æ ·æœ¬æ¡ä»¶ä¸‹å®Œæˆå…¨å›¾è®¡æ•°ä¸æ£€æµ‹ã€‚


|  |  |  |
| :---: | :---: | :---: |
| ![1](demo_pic/1.png) | ![2](demo_pic/2.png) | ![3](demo_pic/3.png) |
| ![4](demo_pic/4.png) | ![5](demo_pic/5.png) | ![6](demo_pic/6.png) |
| ![7](demo_pic/7.png) | ![8](demo_pic/8.png) | ![9](demo_pic/9.png) |
| ![10](demo_pic/10.png) | ![11](demo_pic/11.png) | ![12](demo_pic/12.png) |

> *æ³¨ï¼šé»„è‰²æ¡†ä¸ºç”¨æˆ·æä¾›çš„ Exemplarï¼Œæ©™è‰²æ¡†ä¸ºæ¨¡å‹æ£€æµ‹å‡ºçš„ç›®æ ‡ã€‚*

---

## <a name="introduction"></a>ğŸ“– ç®€ä»‹ (Introduction)

**RF-DETR-FSCD** æ˜¯ä¸€ä¸ª **Class-Agnosticï¼ˆç±»åˆ«æ— å…³ï¼‰** çš„å°‘æ ·æœ¬è®¡æ•°æ£€æµ‹å™¨ã€‚å®ƒåœ¨åŸå§‹ RF-DETR (ICLR 2026) çš„åŸºç¡€ä¸Šè¿›è¡Œäº†æ·±åº¦æ”¹é€ ï¼Œä½¿å…¶ä¸å†å±€é™äº COCO 80 ç±»ï¼Œè€Œæ˜¯èƒ½å¤Ÿæ ¹æ®ç”¨æˆ·æç¤ºï¼ˆPromptsï¼‰åŠ¨æ€æ£€æµ‹ä»»æ„ç±»åˆ«çš„ç›®æ ‡ã€‚

### æ ¸å¿ƒç‰¹æ€§

* **One-Shot Counting:** ç»™å®šä¸€å¼ å›¾ç‰‡å’Œ **1 ä¸ªç¤ºä¾‹æ¡†**ï¼Œè‡ªåŠ¨è®¡æ•°åŒç±»ç‰©ä½“ã€‚
* **Soft Count Optimization:** å¼•å…¥åŸºäº Sigmoid å“åº”å’Œçš„è®¡æ•°æŸå¤±ï¼Œå¤§å¹…æå‡å¯†é›†åœºæ™¯ä¸‹çš„è®¡æ•°ç²¾åº¦ã€‚
* **Real-time Performance:** ç»§æ‰¿ RF-DETR çš„é«˜æ•ˆæ¶æ„ï¼Œæ”¯æŒå®æ—¶æ¨ç†ã€‚

---

## <a name="model-architecture"></a>ğŸ—ï¸ æ ¸å¿ƒæ¶æ„ (Model Architecture)

æ¨¡å‹ä» `LWDETR` æ¼”è¿›ä¸º `FscdLWDETR`ï¼Œä¸»è¦åŒ…å«ä»¥ä¸‹æ”¹é€ ï¼š

### 1. Exemplar Prototype Extractor

ä»ç”¨æˆ·æä¾›çš„ **å• Exemplar Box** ä¸­æå–ç‰¹å¾ï¼š

* **RoI Align:** åœ¨æœ€é«˜åˆ†è¾¨ç‡ç‰¹å¾å›¾ä¸Šæˆªå– 7x7 ç‰¹å¾ã€‚
* **Projection:** ç» `Linear` + `LayerNorm` æŠ•å½±ï¼Œç”Ÿæˆä»£è¡¨è¯¥ç±»åˆ«çš„ **Prototype** å‘é‡ã€‚

### 2. Exemplar Conditioning Module (FiLM)

å°† Prototype æ³¨å…¥ Transformer Decoderï¼š

* ç”Ÿæˆç¼©æ”¾å› å­ () å’Œåç§»é‡ ()ã€‚
* å¯¹å¤šå°ºåº¦ç‰¹å¾å›¾æ‰§è¡Œ **FiLM (Feature-wise Linear Modulation)** æ“ä½œï¼šã€‚
* ä½¿ Decoder åœ¨"çŸ¥é“è¦æ‰¾ä»€ä¹ˆ"çš„æ¡ä»¶ä¸‹å·¥ä½œã€‚

### 3. Prototype-enhanced Objectness

æ”¹é€ åˆ†ç±»å¤´ä»¥é€‚åº” Class-Agnostic ä»»åŠ¡ï¼š

* **Query å¢å¼º:** è®¡ç®— Transformer Query ä¸ Prototype çš„ **ä½™å¼¦ç›¸ä¼¼åº¦ (Cosine Similarity)**ã€‚
* **æœ€ç»ˆå¾—åˆ†:** ã€‚
* **åˆ†ç±»å¤´å˜æ›´:** è¾“å‡ºç»´åº¦ä» 80 (COCO) å˜ä¸º 1 (Binary Objectness)ã€‚

---

## <a name="loss-functions"></a>ğŸ“‰ æŸå¤±å‡½æ•° (Loss Functions)

| æŸå¤±é¡¹ | åŸå§‹ RF-DETR | **RF-DETR-FSCD** | è¯´æ˜ |
| --- | --- | --- | --- |
| **Classification** | Multi-class Focal | **Binary Focal Loss** | , ä»…åŒºåˆ†å‰æ™¯/èƒŒæ™¯ã€‚ |
| **Counting** | N/A | **L1 Soft Count** | ã€‚ |
| **Regression** | L1 + GIoU | L1 + GIoU | ä¿æŒä¸å˜ã€‚ |

---

## <a name="installation"></a>âš™ï¸ å®‰è£…ä¸å‡†å¤‡ (Installation)

```bash
# 1. å…‹éš†ä»£ç 
git clone https://github.com/yourusername/rf-detr-fscd.git
cd rf-detr-fscd

# 2. å®‰è£…ç¯å¢ƒ
pip install -r requirements.txt
# ç¼–è¯‘ CUDA ç®—å­ (å¦‚æœéœ€è¦)
pip install -e .

```

### æ•°æ®é›†å‡†å¤‡ (FSCD-147)

è¯·ç¡®ä¿æ•°æ®é›†ç›®å½•ç»“æ„å¦‚ä¸‹ï¼Œå¹¶æ›´æ–° `config.py` ä¸­çš„è·¯å¾„ï¼š

```text
data/
  FSCD147/
    images_560x560/  # ç»Ÿä¸€ Resize åˆ° 560x560
    annotation/
      instances_val.json
      instances_test.json

```

---

## <a name="training"></a>ğŸš€ è®­ç»ƒ (Training)

ä½¿ç”¨ `TrainFscd.py` å¯åŠ¨è®­ç»ƒã€‚æ¨¡å‹ä¼šè‡ªåŠ¨åŠ è½½ `rf-detr-base.pth` é¢„è®­ç»ƒæƒé‡ï¼ˆè·³è¿‡ä¸åŒ¹é…çš„åˆ†ç±»å¤´å’Œæ–°å¢æ¨¡å—ï¼‰ã€‚

### å…³é”®é…ç½®

* **å­¦ä¹ ç‡ç­–ç•¥:**
* Backbone (DINOv2): `1e-5`
* Decoder / Heads: `5e-5`
* **Schedule:** 3 Epoch Warmup + Cosine Decayã€‚


* **Group DETR:** è®­ç»ƒæ—¶ä½¿ç”¨ 13 ç»„ Queries (3900ä¸ª) åŠ é€Ÿæ”¶æ•›ï¼Œæ¨ç†æ—¶ä»…ç”¨ 300 ä¸ªã€‚

```bash
python TrainFscd.py \
  --config-file config/rf_detr_fscd_config.py \
  --coco_path /path/to/fscd147 \
  --output_dir output/fscd_v1 \
  --batch_size 4

```

---

## <a name="inference"></a>ğŸ“Š æ¨ç†ä¸è¯„ä¼° (Inference)

### 1. äº¤äº’å¼ Demo

å¯åŠ¨ GUI ç•Œé¢ï¼Œé€šè¿‡é¼ æ ‡ç”» **1ä¸ªæ¡†** è¿›è¡Œå®æ—¶è®¡æ•°ï¼š

```bash
python DemoFscd.py \
  --resume output/fscd_v1/checkpoint.pth \
  --image_path assets/test_image.jpg

```

### 2. ç²¾åº¦è¯„ä¼°

è®¡ç®— MAE (Mean Absolute Error) å’Œ RMSEã€‚è¯„ä¼°æ—¶é‡‡ç”¨ **Soft Count** (sigmoidæ±‚å’Œ) ä»¥è·å¾—æ›´é²æ£’çš„ç»“æœã€‚

```bash
python EvalFscd.py \
  --coco_path /path/to/fscd147 \
  --resume output/fscd_v1/checkpoint.pth \
  --eval_set test

```

---

<a name="future-work"></a>ğŸ“… åç»­è®¡åˆ’ (Future Work)
å½“å‰ç‰ˆæœ¬å±•ç¤ºäº† RF-DETR åœ¨å°‘æ ·æœ¬è®¡æ•°ä»»åŠ¡ä¸Šçš„æ½œåŠ›ï¼Œä½†ä»æœ‰ä¼˜åŒ–ç©ºé—´ã€‚æˆ‘ä»¬è®¡åˆ’åœ¨æœªæ¥ç‰ˆæœ¬ä¸­é€šè¿‡ä»¥ä¸‹æ–¹å¼è¿›ä¸€æ­¥æå‡æ€§èƒ½ï¼š

[ ] ä¼˜åŒ–è¾¹ç•Œæ¡†æŸå¤± (Refine BBox Loss): è®¡åˆ’æ”¹è¿›å›å½’æŸå¤±å‡½æ•°ï¼ˆå¦‚å¼•å…¥ CIoU æˆ– DIoUï¼‰ï¼Œä»¥è¿›ä¸€æ­¥æå‡æ£€æµ‹æ¡†çš„å®šä½ç²¾åº¦ (IoU)ã€‚

[ ] å¼•å…¥ NMS åå¤„ç† (Post-processing): æ¢ç´¢åœ¨æ¨ç†é˜¶æ®µåŠ å…¥éæå¤§å€¼æŠ‘åˆ¶ (Non-Maximum Suppression)ï¼Œä»¥å‡å°‘å¯†é›†åœºæ™¯ä¸‹çš„é‡å é¢„æµ‹æ¡†ã€‚

[ ] å¢åŠ è®­ç»ƒè½®æ¬¡ (Longer Training): ç›®å‰æä¾›çš„æƒé‡ä»…è®­ç»ƒäº† 9 ä¸ª Epochã€‚æˆ‘ä»¬è®¡åˆ’è¿›è¡Œæ›´é•¿æ—¶é—´çš„è®­ç»ƒï¼Œä»¥å……åˆ†æŒ–æ˜æ¨¡å‹æ½œåŠ›å¹¶æå‡æ³›åŒ–èƒ½åŠ›ã€‚

## Acknowledgement

* Base model: [RF-DETR](https://www.google.com/search?q=https://github.com/roboflow/rf-detr)
* Dataset: [FSCD-147](https://www.google.com/search?q=https://github.com/VisWan/FSC-147)

# RF-DETR â†’ FSCD å®Œæ•´æ”¹é€ æŠ€æœ¯æ–‡æ¡£

> **é¡¹ç›®ä»“åº“**ï¼š[Yes-buter/RF-DETR-FSCD](https://github.com/Yes-buter/RF-DETR-FSCD)  
> **åŸºç¡€æ¨¡å‹**ï¼š[roboflow/rf-detr](https://github.com/roboflow/rf-detr)ï¼ˆRF-DETRï¼ŒICLR 2026ï¼‰  
> **ç›®æ ‡ä»»åŠ¡**ï¼šFSCDï¼ˆFew-Shot Counting and Detectionï¼Œå°‘æ ·æœ¬ç›®æ ‡è®¡æ•°ä¸æ£€æµ‹ï¼‰  
> **ç›®æ ‡æ•°æ®é›†**ï¼šFSCD-147ã€FSCD-LVIS  
> **æ–‡æ¡£æ—¥æœŸ**ï¼š2026-02-24  

---

## ç›®å½•

1. [é¡¹ç›®æ¦‚è¿°](#1-é¡¹ç›®æ¦‚è¿°)
2. [åŸå§‹ RF-DETR æ¶æ„åŸºç¡€](#2-åŸå§‹-rf-detr-æ¶æ„åŸºç¡€)
3. [FSCD ä»»åŠ¡å®šä¹‰](#3-fscd-ä»»åŠ¡å®šä¹‰)
4. [æ–°å¢ï¿½ï¿½ä¿®æ”¹çš„æ–‡ä»¶æ¸…å•](#4-æ–°å¢ä¸ä¿®æ”¹çš„æ–‡ä»¶æ¸…å•)
5. [æ ¸å¿ƒæ¨¡å‹æ”¹é€ ï¼šLWDETR â†’ FscdLWDETR](#5-æ ¸å¿ƒæ¨¡å‹æ”¹é€ lwdetr--fscdlwdetr)
6. [æŸå¤±å‡½æ•°æ”¹é€ ](#6-æŸå¤±å‡½æ•°æ”¹é€ )
7. [åŒˆç‰™åˆ© Matcher æ”¹é€ ](#7-åŒˆç‰™åˆ©-matcher-æ”¹é€ )
8. [æ•°æ®é›†åŠ è½½å™¨ï¼šFscd147Dataset](#8-æ•°æ®é›†åŠ è½½å™¨fscd147dataset)
9. [æ•°æ®å¢å¼ºæ”¹é€ ](#9-æ•°æ®å¢å¼ºæ”¹é€ )
10. [è®­ç»ƒæµç¨‹è®¾è®¡](#10-è®­ç»ƒæµç¨‹è®¾è®¡)
11. [è¯„ä¼°æŒ‡æ ‡ä½“ç³»](#11-è¯„ä¼°æŒ‡æ ‡ä½“ç³»)
12. [é…ç½®ç³»ç»Ÿæ”¹é€ ](#12-é…ç½®ç³»ç»Ÿæ”¹é€ )
13. [æƒé‡åŠ è½½ç­–ç•¥](#13-æƒé‡åŠ è½½ç­–ç•¥)
14. [æ¨ç†ä¸å·¥å…·è„šæœ¬](#14-æ¨ç†ä¸å·¥å…·è„šæœ¬)
15. [ç¯å¢ƒé…ç½®](#15-ç¯å¢ƒé…ç½®)
16. [ä¼˜åŒ–è°ƒå‚å†ç¨‹](#16-ä¼˜åŒ–è°ƒå‚å†ç¨‹)
17. [å®éªŒç»“æœè®°å½•](#17-å®éªŒç»“æœè®°å½•)
18. [å·²çŸ¥é—®é¢˜ä¸åç»­æ–¹å‘](#18-å·²çŸ¥é—®é¢˜ä¸åç»­æ–¹å‘)
19. [å…³é”® Bug è®°å½•](#19-å…³é”®-bug-è®°å½•)

---

## 1. é¡¹ï¿½ï¿½ï¿½æ¦‚è¿°

### 1.1 æ”¹é€ åŠ¨æœº

RF-DETR æ˜¯ Roboflow å‘å¸ƒçš„é«˜æ€§èƒ½å®æ—¶ç›®æ ‡æ£€æµ‹æ¨¡å‹ï¼ˆåœ¨ COCO ä¸Š Base ç‰ˆè¾¾åˆ° 53.2 APï¼ŒLarge ç‰ˆè¾¾åˆ° 57.4 APï¼‰ã€‚å…¶æ ¸å¿ƒä¼˜åŠ¿åŒ…æ‹¬ï¼š

- **DINOv2 Backbone**ï¼šå¼ºå¤§çš„è‡ªç›‘ç£è§†è§‰ç‰¹å¾ï¼Œæ³›åŒ–èƒ½åŠ›å‡ºè‰²
- **LW-DETR è§£ç å™¨**ï¼šåŸºäºå¯å˜å½¢æ³¨æ„åŠ›çš„è½»é‡çº§ Transformer è§£ç å™¨
- **Group DETR**ï¼šè®­ç»ƒæ—¶ä½¿ç”¨å¤šç»„ query åŠ é€Ÿæ”¶æ•›

ç„¶è€Œï¼ŒRF-DETR æ˜¯ä¸€ä¸ª**å°é—­é›†ï¼ˆClosed-Setï¼‰å¤šç±»åˆ«æ£€æµ‹æ¨¡å‹**ï¼Œé’ˆå¯¹å›ºå®šçš„ 80 ä¸ª COCO ç±»åˆ«ï¼Œæ— æ³•å¤„ç† FSCD ä»»åŠ¡ä¸­"æµ‹è¯•æ—¶ç±»åˆ«æœªçŸ¥"çš„åœºæ™¯ã€‚

### 1.2 æ”¹é€ ç›®æ ‡

å°† RF-DETR æ”¹é€ ä¸ºæ”¯æŒ FSCD ä»»åŠ¡çš„æ¨¡å‹ï¼š

| èƒ½åŠ› | åŸå§‹ RF-DETR | RF-DETR-FSCD |
|------|-------------|--------------|
| åˆ†ç±»æ–¹å¼ | å›ºå®š 80 ç±» | Class-Agnosticï¼ˆç±»åˆ«æ— å…³ï¼‰|
| é¢å¤–è¾“å…¥ | æ—  | 1~3 ä¸ª Exemplar Bounding Box |
| è¾“å‡º | æ£€æµ‹æ¡† + ç±»åˆ« | æ£€æµ‹æ¡† + ç›®æ ‡è®¡æ•° |
| è®­ç»ƒæ•°æ®é›† | COCO | FSCD-147 |

### 1.3 å‚è€ƒæ¨¡å‹

| æ¨¡å‹ | æ ¸å¿ƒæ€è·¯ | å‚è€ƒç‚¹ |
|------|---------|--------|
| **Counting-DETR** | åŸºäº DETRï¼Œä½¿ç”¨ exemplar ç‰¹å¾å¢å¼º decoder query | æ•´ä½“æ¡†æ¶ |
| **DAVE** | ä¸¤é˜¶æ®µï¼šå…ˆç²—æ£€æµ‹ï¼Œå†ç”¨ exemplar éªŒè¯ | å¤šé˜¶æ®µè®¾è®¡ |
| **GeCo** | SAM ç”Ÿæˆ exemplar åŸå‹ï¼Œdense query | åŸå‹æå–æ–¹å¼ |

---

## 2. åŸå§‹ RF-DETR æ¶æ„åŸºç¡€

### 2.1 æ•´ä½“æ¶æ„ï¼ˆBase ç‰ˆæœ¬ï¼‰

```
è¾“å…¥å›¾åƒ [B, 3, H, W]
    â”‚
    â–¼
DINOv2 Backboneï¼ˆViT-Sï¼ŒWindowed Attentionï¼‰
    â”‚  å¤šå°ºåº¦ç‰¹å¾å›¾
    â–¼
Projectorï¼ˆé€šé“é™ç»´ + å¤šå°ºåº¦å¯¹é½ï¼‰
    â”‚  [B, 256, H/8, W/8], [B, 256, H/16, W/16]...
    â–¼
LW-DETR Transformer Decoder
  â”œâ”€ Two-Stageï¼šå…ˆç”Ÿæˆ encoder proposalsï¼ˆnum_select=300ï¼‰
  â”œâ”€ Group DETRï¼šè®­ç»ƒæ—¶ query Ã— 13 = 3900 ä¸ªï¼Œæ¨ç†æ—¶ä»…ç”¨ 300 ä¸ª
  â””â”€ å¯å˜å½¢äº¤å‰æ³¨æ„åŠ›ï¼ˆDeformable Cross-Attentionï¼‰
    â”‚
    â–¼
æ£€æµ‹å¤´
  â”œâ”€ class_embedï¼šLinear(256 â†’ 80)   â† æ”¹é€ ä¸º ObjectnessEmbed: Linear(256 â†’ 1)
  â””â”€ bbox_embedï¼š MLP(256 â†’ 4)       â† ä¿ç•™ä¸å˜
```

### 2.2 å…³é”®è¶…å‚æ•°ï¼ˆBase vs Largeï¼‰

| å‚æ•° | Base | Large | è¯´æ˜ |
|------|------|-------|------|
| `encoder` | `dinov2_windowed_small` | `dinov2_windowed_base` | Backbone è§„æ ¼ |
| `hidden_dim` | 256 | 384 | Transformer éšå±‚ç»´åº¦ |
| `num_queries` | 300 | 300 | æ¨ç†æ—¶çš„ query æ•° |
| `num_select` | 300 | 300 | Two-stage ç¬¬ä¸€é˜¶æ®µå€™é€‰æ•° |
| `dec_layers` | 6 | 6 | Decoder å±‚æ•° |
| `sa_nheads` | 8 | 12 | Self-attention å¤´æ•° |
| `ca_nheads` | 16 | 24 | Cross-attention å¤´æ•° |
| `dec_n_points` | 2 | 4 | å¯å˜å½¢æ³¨æ„åŠ›é‡‡æ ·ç‚¹æ•° |
| `group_detr` | 13 | 13 | è®­ç»ƒ query åˆ†ç»„æ•° |
| `projector_scale` | `["P4"]` | `["P3","P5"]` | å¤šå°ºåº¦æŠ•å½±å±‚ |
| `pretrain_weights` | `rf-detr-base.pth` | `rf-detr-large.pth` | é¢„è®­ç»ƒæƒé‡ |

---

## 3. FSCD ä»»åŠ¡å®šä¹‰

### 3.1 ä»»åŠ¡æè¿°

**Few-Shot Counting and Detectionï¼ˆFSCDï¼‰**ï¼šç»™å®šä¸€å¼ å›¾åƒå’Œ 1~3 ä¸ª exemplar bounding boxï¼ˆæ¡†å‡º"è¦æ•°ä»€ä¹ˆ"ï¼‰ï¼Œæ¨¡å‹éœ€è¦ï¼š

1. æ£€æµ‹å‡ºå›¾ä¸­æ‰€æœ‰åŒç±»ç›®æ ‡çš„è¾¹ç•Œæ¡†
2. è¾“å‡ºç›®æ ‡æ€»æ•°ï¼ˆè®¡æ•°ï¼‰
3. ç±»åˆ«æ˜¯ class-agnosticï¼ˆä¸ä¾èµ–é¢„å®šä¹‰ç±»åˆ«æ ‡ç­¾ï¼‰

### 3.2 FSCD-147 æ•°æ®é›†

```
FSCD147/
â”œâ”€â”€ images_384_VarV2/                               # å›¾åƒï¼ˆ384 åˆ†è¾¨ç‡ï¼Œå¯å˜ï¼‰
â”œâ”€â”€ gt_density_map_adaptive_512_512_object_VarV2/   # å¯†åº¦å›¾ï¼ˆæœªç›´æ¥ä½¿ç”¨ï¼‰
â”œâ”€â”€ annotation_FSC147_384.json                      # ä¸»æ ‡æ³¨æ–‡ä»¶
â”œâ”€â”€ Train_Test_Val_FSC_147.json                     # æ•°æ®é›†åˆ’åˆ†
â”œâ”€ï¿½ï¿½ instances_val.json                              # COCO æ ¼å¼éªŒè¯é›†æ ‡æ³¨
â””â”€â”€ instances_test.json                             # COCO æ ¼å¼æµ‹è¯•é›†æ ‡æ³¨
```

**æ•°æ®é›†è§„æ¨¡**ï¼š
- Trainï¼š3659 å¼ 
- Valï¼š1286 å¼ 
- Testï¼š1190 å¼ 

**`annotation_FSC147_384.json` æ ¼å¼**ï¼š

```json
{
  "image_filename.jpg": {
    "H": 384,
    "W": 512,
    "box_examples_coordinates": [
      [[y1,x1], [y2,x2], [y3,x3], [y4,x4]],
      [[y1,x1], [y2,x2], [y3,x3], [y4,x4]],
      [[y1,x1], [y2,x2], [y3,x3], [y4,x4]]
    ],
    "points": [[x,y], [x,y], ...],
    "density_path": "...",
    "ratio_h": 1.0,
    "ratio_w": 1.0
  }
}
```

> âš ï¸ **é‡è¦**ï¼š`box_examples_coordinates` ä½¿ç”¨ 4 ä¸ªè§’ç‚¹è¡¨ç¤ºï¼Œåæ ‡é¡ºåºä¸º `[y, x]`ï¼ˆä¸å¸¸è§ `[x, y]` ç›¸åï¼‰ï¼Œè§£ææ—¶éœ€äº¤æ¢åæ ‡è½´ã€‚

---

## 4. æ–°å¢ä¸ä¿®æ”¹çš„æ–‡ä»¶æ¸…å•

### 4.1 æ–°å»ºæ–‡ä»¶

| æ–‡ä»¶è·¯å¾„ | è¯´æ˜ |
|---------|------|
| `rf-detr/rfdetr/models/FscdDetr.py` | FSCD æ ¸å¿ƒæ¨¡å‹ï¼ˆ`FscdLWDETR`ã€`FscdSetCriterion`ã€`FscdPostProcess`ã€`BuildFscdCriterionAndPostprocessors`ï¼‰ |
| `rf-detr/rfdetr/models/Exemplar.py` | Exemplar ç‰¹å¾æå–ä¸ FiLM æ¡ä»¶åŒ–æ¨¡å—ï¼ˆ`ExemplarPrototypeExtractor`ã€`ExemplarConditioningModule`ï¼‰ |
| `rf-detr/rfdetr/FscdMain.py` | æ¨¡å‹ç®¡ç†ç±»ï¼ˆ`FscdModel`ï¼‰ï¼Œè´Ÿè´£æ¨¡å‹æ„å»ºä¸é¢„è®­ç»ƒæƒé‡åŠ è½½ |
| `rf-detr/rfdetr/FscdEngine.py` | è®­ç»ƒ/è¯„ä¼°å¼•æ“ï¼ˆ`FscdTrainOneEpoch`ã€`FscdEvaluate`ã€`ScanThreshold`ï¼‰ |
| `rf-detr/rfdetr/datasets/Fscd147.py` | FSCD-147 æ•°æ®é›†åŠ è½½å™¨ï¼ˆ`Fscd147Dataset`ã€`BuildFscd147`ï¼‰ |
| `rf-detr/TrainFscd.py` | å®Œæ•´è®­ç»ƒå¯åŠ¨è„šæœ¬ï¼ˆCLI + è®­ç»ƒå¾ªç¯ + è¯„ä¼° + æ–­ç‚¹ç»­è®­ï¼‰ |
| `rf-detr/DemoFscd.py` | äº¤äº’å¼æ¨ç†æ¼”ç¤ºï¼ˆOpenCV é¼ æ ‡ç”»æ¡† â†’ æ¨ç† â†’ å¯è§†åŒ–ï¼‰ |
| `rf-detr/EvalFscd.py` | æ ‡å‡† Benchmark è¯„ä¼°è„šæœ¬ï¼ˆFSCD-147 / FSCD-LVISï¼Œå…¨å¥—æŒ‡æ ‡ï¼‰ |

### 4.2 ä¿®æ”¹çš„åŸæœ‰æ–‡ä»¶

| æ–‡ä»¶è·¯å¾„ | ä¿®æ”¹å†…å®¹ |
|---------|---------|
| `rf-detr/rfdetr/config.py` | æ–°å¢ `RFDETRFSCDConfig`ã€`RFDETRFSCDLargeConfig`ã€`FSCDTrainConfig` |
| `rf-detr/rfdetr/detr.py` | æ–°å¢ `RFDETRFSCD` ç±»ï¼ˆå¯¹å¤– APIï¼‰ |
| `rf-detr/rfdetr/__init__.py` | å¯¼å‡º `RFDETRFSCD` |
| `rf-detr/rfdetr/datasets/__init__.py` | æ³¨å†Œ `"fscd147"` æ•°æ®é›†è·¯ç”± |
| `rf-detr/rfdetr/datasets/transforms.py` | ä¿®å¤ `crop`/`hflip`/`SquareResize` å¯¹ `exemplar_boxes` å’Œ `points` çš„æ”¯æŒï¼›æ–°å¢ `PhotometricDistort` |
| `rf-detr/rfdetr/models/matcher.py` | `focal_alpha`/`focal_gamma` æ”¹ä¸ºå¯é…ç½®å‚æ•° |
| `rf-detr/pyproject.toml` | é…ç½® PyTorch CUDA ç´¢å¼•æºï¼Œå‡çº§ `transformers >= 4.44` |

---

## 5. æ ¸å¿ƒæ¨¡å‹æ”¹é€ ï¼šLWDETR â†’ FscdLWDETR

### 5.1 æ”¹é€ æ€»è§ˆ

```
åŸå§‹ LWDETRï¼š
  å›¾åƒ â†’ Backbone â†’ Projector â†’ Transformer â†’ class_embed(80) + bbox_embed

FscdLWDETRï¼š
  å›¾åƒ + ExemplarBoxes
    â”‚           â”‚
    â–¼           â–¼
  Backbone   ExemplarPrototypeExtractorï¼ˆæ–°å¢ï¼‰
    â”‚               â”‚ Prototype [B, HiddenDim]
    â–¼               â–¼
  Projector â†’ ExemplarConditioningModuleï¼ˆæ–°å¢ï¼ŒFiLMï¼‰
    â”‚  æ¡ä»¶åŒ–åçš„å¤šå°ºåº¦ç‰¹å¾å›¾
    â–¼
  Transformer Decoder
    â”‚  Query ç‰¹å¾ [B, NQ, HiddenDim]
    â–¼
  ProtoProjectionï¼ˆæ–°å¢ï¼‰â†’ Cosine Similarity
    â”‚
    â–¼
  ObjectnessEmbed(1) + CosineSim + bbox_embed(4)
```

### 5.2 æ–°å¢æ¨¡å—ä¸€ï¼šExemplarPrototypeExtractor

**æ–‡ä»¶**ï¼š`rfdetr/models/Exemplar.py`

**åŠŸèƒ½**ï¼šä» exemplar bounding box ä¸­æå–ä»£è¡¨"è¦æ‰¾ä»€ä¹ˆ"çš„åŸå‹å‘é‡ã€‚

**ç»“æ„**ï¼š

```python
class ExemplarPrototypeExtractor(nn.Module):
    def __init__(self, HiddenDim, PoolSize=7, PrototypeDim=256):
        self.RoiAlign = torchvision.ops.roi_align
        self.Proj     = nn.Linear(HiddenDim * PoolSize * PoolSize, PrototypeDim)
        self.Norm     = nn.LayerNorm(PrototypeDim)

    def forward(self, MultiScaleFeats, ExemplarBoxes):
        # ExemplarBoxes: [B, K, 4]ï¼ˆxyxy ç»å¯¹åæ ‡ï¼‰
        # é€‰å–æœ€é«˜åˆ†è¾¨ç‡ï¼ˆstride æœ€å°ï¼‰çš„ç‰¹å¾å›¾
        Feat = MultiScaleFeats[0]           # [B, C, H, W]

        # æ„å»º RoI Align æ‰€éœ€æ ¼å¼
        Rois = build_rois(ExemplarBoxes)    # [(batch_idx, x1, y1, x2, y2), ...]

        # RoI Alignï¼šæ¯ä¸ª exemplar æå– PoolSizeÃ—PoolSize ç‰¹å¾
        Pooled = self.RoiAlign(Feat, Rois,
                               output_size=(self.PoolSize, self.PoolSize),
                               spatial_scale=1.0 / Stride)
        # Pooled: [B*K, C, PoolSize, PoolSize]

        # Flatten + æŠ•å½±
        Pooled = Pooled.flatten(1)                  # [B*K, C*P*P]
        Proto  = self.Norm(self.Proj(Pooled))        # [B*K, PrototypeDim]

        # Reshape å¹¶å¯¹ K ä¸ª exemplar æ±‚å¹³å‡
        Proto  = Proto.view(B, K, -1).mean(dim=1)   # [B, PrototypeDim]
        return Proto
```

**è®¾è®¡è¦ç‚¹**ï¼š
- åœ¨**æœ€é«˜åˆ†è¾¨ç‡**ç‰¹å¾å›¾ä¸Šåš RoI Alignï¼Œä¿ç•™æœ€ç»†ç²’åº¦çš„å±€éƒ¨çº¹ç†ä¿¡æ¯
- å¤šä¸ª exemplar ç‰¹å¾**å¹³å‡**å¾—åˆ°æœ€ç»ˆåŸå‹ï¼Œä¿æŒå¯¹ exemplar æ•°é‡ï¼ˆ1~3 ä¸ªï¼‰çš„çµæ´»æ€§
- `LayerNorm` ç¨³å®šè®­ç»ƒåˆæœŸçš„ç‰¹å¾å¹…åº¦

### 5.3 æ–°å¢æ¨¡å—äºŒï¼šExemplarConditioningModule

**æ–‡ä»¶**ï¼š`rfdetr/models/Exemplar.py`

**åŠŸèƒ½**ï¼šå°† Prototype å‘é‡æ³¨å…¥å¤šå°ºåº¦ç‰¹å¾å›¾ï¼Œä½¿ Transformer Decoder åœ¨"çŸ¥é“è¦æ‰¾ä»€ä¹ˆ"çš„æ¡ä»¶ä¸‹å¤„ç†å›¾åƒç‰¹å¾ã€‚

**æ–¹æ³•**ï¼šFiLMï¼ˆFeature-wise Linear Modulationï¼‰

```python
class ExemplarConditioningModule(nn.Module):
    def __init__(self, HiddenDim, NumHeads=8, NumScales=3):
        self.ScaleProj = nn.Linear(HiddenDim, HiddenDim)
        self.ShiftProj = nn.Linear(HiddenDim, HiddenDim)

    def forward(self, MultiScaleFeats, Prototype):
        # Prototype: [B, HiddenDim]
        Scale = self.ScaleProj(Prototype)               # [B, HiddenDim]
        Shift = self.ShiftProj(Prototype)               # [B, HiddenDim]

        CondFeats = []
        for Feat in MultiScaleFeats:
            # å¹¿æ’­åˆ°ç©ºé—´ç»´åº¦
            S = Scale.unsqueeze(-1).unsqueeze(-1)       # [B, C, 1, 1]
            T = Shift.unsqueeze(-1).unsqueeze(-1)       # [B, C, 1, 1]

            # FiLM æ“ä½œï¼šoutput = src Ã— scale + shift
            CondFeats.append(Feat * S + T)

        return CondFeats
```

**è®¾è®¡è¦ç‚¹**ï¼š
- å¯¹ Projector è¾“å‡ºçš„**æ¯ä¸ªå°ºåº¦**çš„ç‰¹å¾å›¾éƒ½åšæ¡ä»¶åŒ–ï¼Œç¡®ä¿æ‰€æœ‰å°ºåº¦éƒ½æºå¸¦ exemplar ä¿¡æ¯
- FiLM æ˜¯ä¸€ç§è½»é‡çš„æ¡ä»¶æ³¨å…¥æ–¹å¼ï¼Œå‚æ•°é‡æå°ï¼ˆä»…ä¸¤ä¸ª Linear å±‚ï¼‰
- **å·²çŸ¥é—®é¢˜**ï¼šåˆå§‹åŒ–æ—¶ Scaleâ‰ˆéšæœºã€Shiftâ‰ˆéšæœºï¼Œå¯èƒ½ç ´åé¢„è®­ç»ƒç‰¹å¾ã€‚åç»­æ”¹è¿›æ–¹å‘æ˜¯æ”¹ä¸ºæ®‹å·®å½¢å¼ `Feat * (1 + Scale) + Shift`

### 5.4 æ–°å¢æ¨¡å—ä¸‰ï¼šProtoProjection + Cosine Similarity

**ä½ç½®**ï¼š`rfdetr/models/FscdDetr.py` ä¸­ `FscdLWDETR.forward()`

**åŠŸèƒ½**ï¼šè®¡ç®—æ¯ä¸ª Decoder Query ä¸ Prototype çš„ä½™å¼¦ç›¸ä¼¼åº¦ï¼Œå åŠ åˆ° objectness logit ä¸Šï¼Œä½¿ä¸ exemplar è¶Šç›¸ä¼¼çš„ query æœ€ç»ˆåˆ†æ•°è¶Šé«˜ã€‚

```python
# ProtoProjection å®šä¹‰
self.ProtoProjection = nn.Linear(HiddenDim, PrototypeDim)

# åœ¨ forward ä¸­ï¼ˆæ¯ä¸ª decoder å±‚è¾“å‡ºåï¼‰
QueryFeats = HS[-1]                                   # [B, NQ, HiddenDim]
ProjQuery  = self.ProtoProjection(QueryFeats)         # [B, NQ, PrototypeDim]
ProjProto  = Prototype.unsqueeze(1)                   # [B, 1, PrototypeDim]

CosineSim  = F.cosine_similarity(ProjQuery, ProjProto, dim=-1)  # [B, NQ]

# åˆ†ç±»å¤´
ObjectnessLogit = self.ObjectnessEmbed(QueryFeats)    # [B, NQ, 1]
FinalLogit = ObjectnessLogit + CosineSim.unsqueeze(-1)
```

**æœ€ç»ˆå¾—åˆ†å…¬å¼**ï¼š

```
score = sigmoid(ObjectnessEmbed(query) + cosine_similarity(ProtoProj(query), Prototype))
```

### 5.5 åˆ†ç±»å¤´æ›¿æ¢

| åŸå§‹ | æ”¹é€ å |
|------|-------|
| `class_embed = nn.Linear(hidden_dim, 80)` | `ObjectnessEmbed = nn.Linear(hidden_dim, 1)` |

**Bias åˆå§‹åŒ–ï¼ˆå…³é”®ï¼‰**ï¼š

```python
# prior_prob å¯é…ç½®ï¼Œé»˜è®¤ 0.01
PriorProb = self.PriorProb
BiasValue = -math.log((1 - PriorProb) / PriorProb)  # â‰ˆ -4.595ï¼ˆå½“ prior=0.01ï¼‰
self.ObjectnessEmbed.bias.data = torch.ones(1) * BiasValue
```

**åŸå› **ï¼šè¿™æ˜¯ RetinaNet/DETR æ ‡å‡†åšæ³•ã€‚åˆå§‹åŒ–åæ¯ä¸ª query çš„ `sigmoid(logit) â‰ˆ prior_prob = 0.01`ï¼Œè®­ç»ƒåˆæœŸ loss å¹³ç¨³ï¼Œé¿å…æ¢¯åº¦çˆ†ç‚¸ã€‚

è‹¥ `prior_prob` è®¾ç½®ä¸å½“ï¼ˆå¦‚ä½¿ç”¨é»˜è®¤ 0.5ï¼‰ï¼Œåˆå§‹ loss ä¼šæå¤§ï¼Œæ¨¡å‹ä¸ºäº†å­˜æ´»ä¼šæŠŠæ‰€æœ‰åˆ†æ•°å¼ºè¡Œå‹ä½åˆ° 0ï¼Œå¯¼è‡´é•¿æœŸæ¬ è®¡æ•°ã€‚

### 5.6 å®Œæ•´ Forward æµç¨‹

```python
def forward(self, Samples, ExemplarBoxes, Targets=None):
    # Step 1: Backbone ç‰¹å¾æå–
    Features = self.Backbone(Samples.tensors, Samples.mask)
    # Features: å¤šå°ºåº¦ç‰¹å¾å›¾å­—å…¸

    # Step 2: Projector å¤šå°ºåº¦å¯¹é½
    MultiScaleFeats, Pos = self.Projector(Features)
    # MultiScaleFeats: [[B,256,H1,W1], [B,256,H2,W2], ...]

    # Step 3: Exemplar Prototype æå–ï¼ˆæ–°å¢ï¼‰
    Prototype = self.ExemplarExtractor(MultiScaleFeats, ExemplarBoxes)
    # Prototype: [B, PrototypeDim]

    # Step 4: FiLM ç‰¹å¾æ¡ä»¶åŒ–ï¼ˆæ–°å¢ï¼‰
    MultiScaleFeats = self.ExemplarConditioning(MultiScaleFeats, Prototype)

    # Step 5: Transformer Decoder
    HS, Init_Ref, Inter_Ref, EncOutput, EncOutputClass, EncOutputCoord = \
        self.TransformerModule(MultiScaleFeats, Pos, ...)

    # Step 6: æ¯ä¸ª Decoder å±‚çš„è¾“å‡ºå¤´ï¼ˆå«ä½™å¼¦ç›¸ä¼¼åº¦å¢å¼ºï¼‰
    AllLogits, AllBoxes = [], []
    for hs, ref in zip(HS, Inter_Ref):
        # ä½™å¼¦ç›¸ä¼¼åº¦å¢å¼º
        ProjQ  = self.ProtoProjection(hs)              # [B, NQ, PrototypeDim]
        CosSim = F.cosine_similarity(ProjQ,
                     Prototype.unsqueeze(1), dim=-1)   # [B, NQ]
        Logit  = self.ObjectnessEmbed(hs) + CosSim.unsqueeze(-1)
        Box    = self.bbox_embed[Layer](hs)
        AllLogits.append(Logit)
        AllBoxes.append(Box)

    return {
        "pred_logits":  AllLogits[-1],                 # [B, NQ, 1]
        "pred_boxes":   AllBoxes[-1],                  # [B, NQ, 4]
        "aux_outputs": [{"pred_logits": l, "pred_boxes": b}
                        for l, b in zip(AllLogits[:-1], AllBoxes[:-1])]
    }
```

### 5.7 å‚æ•°é‡ç»Ÿè®¡ï¼ˆBase ç‰ˆæœ¬ï¼‰

| æ¨¡å— | å‚æ•°é‡ | åˆå§‹åŒ–æ–¹å¼ | å­¦ä¹ ç‡ |
|------|--------|-----------|--------|
| `Backbone`ï¼ˆDINOv2 ViT-Sï¼‰ | ~22.1M | COCO é¢„è®­ç»ƒ | 1e-5 |
| `Projector` | ~1.8M | COCO é¢„è®­ç»ƒ | 5e-5 |
| `TransformerModule` | ~7.2M | COCO é¢„è®­ç»ƒ | 5e-5 |
| `ObjectnessEmbed` | ~0.3K | é¢„è®­ç»ƒ class_embed[0] è¡Œ | 5e-5 |
| `ExemplarExtractor`ï¼ˆæ–°å¢ï¼‰ | ~757K | éšæœºåˆå§‹åŒ– | 5e-5 |
| `ExemplarConditioning`ï¼ˆæ–°å¢ï¼‰ | ~855K | éšæœºåˆå§‹åŒ– | 5e-5 |
| `ProtoProjection`ï¼ˆæ–°å¢ï¼‰ | ~65K | éšæœºåˆå§‹åŒ– | 5e-5 |
| **æ€»è®¡** | **~33.5M** | â€” | â€” |

> å…¨éƒ¨å‚æ•°å‡å¯è®­ç»ƒï¼Œæ— å†»ç»“å±‚ã€‚

---

## 6. æŸå¤±å‡½æ•°æ”¹é€ 

### 6.1 æŸå¤±å‡½æ•°å¯¹æ¯”

| æŸå¤±é¡¹ | åŸå§‹ RF-DETR | RF-DETR-FSCD | æƒé‡ |
|--------|-------------|--------------|------|
| **åˆ†ç±»ï¼ˆClassificationï¼‰** | Multi-class Focal Lossï¼ˆ80 ç±»ï¼‰ | Binary Focal Lossï¼ˆ1 ç±»ï¼Œå‰æ™¯/èƒŒæ™¯ï¼‰ | `cls_loss_coef=2` |
| **è¾¹ç•Œæ¡†ï¼ˆBBoxï¼‰** | L1 Loss | L1 Lossï¼ˆä¸å˜ï¼‰ | `bbox_loss_coef=5` |
| **GIoU** | Generalized IoU Loss | GIoU Lossï¼ˆä¸å˜ï¼‰ | `giou_loss_coef=2` |
| **è®¡æ•°ï¼ˆCountï¼‰** | æ—  | Soft Count L1ï¼ˆæ–°å¢ï¼‰ | `count_loss_coef=3.0`ï¼ˆåˆå§‹ 0.5ï¼‰ |

### 6.2 Binary Focal Lossï¼ˆåˆ†ç±»æŸå¤±ï¼‰

```python
def loss_labels(self, outputs, targets, indices, num_boxes, **kwargs):
    SrcLogits = outputs["pred_logits"]      # [B, NQ, 1]

    # æ„å»ºäºŒå€¼ç›®æ ‡ï¼šåŒ¹é…åˆ° GT çš„ query æ ‡ä¸º 1ï¼Œå…¶ä½™ä¸º 0
    TargetClasses = torch.zeros(B, NQ, 1)
    for b, (src_idx, tgt_idx) in enumerate(indices):
        TargetClasses[b, src_idx] = 1.0

    # Sigmoid Focal Loss
    # alpha=0.25 é’ˆå¯¹ç¨€ç–ç›®æ ‡ï¼ˆå¤§å¤šæ•° query æ˜¯èƒŒæ™¯ï¼‰
    # gamma=2.0  å…³æ³¨éš¾åˆ†æ ·æœ¬
    Loss = sigmoid_focal_loss(
        SrcLogits.squeeze(-1),
        TargetClasses.squeeze(-1),
        num_boxes,
        alpha=self.FocalAlpha,    # å¯é…ç½®ï¼Œé»˜è®¤ 0.25
        gamma=self.FocalGamma     # å¯é…ç½®ï¼Œé»˜è®¤ 2.0
    )

    # åŒæ—¶è®°å½•åŒ¹é… query æ•°ï¼ˆç”¨äºè°ƒè¯•ï¼Œå†™å…¥ log.jsonlï¼‰
    MatchedPerImg = (sum(len(s) for s, _ in indices)
                     / len(targets) / self.GroupDetr)

    return {"loss_ce": Loss,
            "matched_queries_per_image": MatchedPerImg}
```

**ä¸åŸå§‹çš„å…³é”®åŒºåˆ«**ï¼š
- åŸå§‹ï¼š`sigmoid_focal_loss(logits, targets)` å…¶ä¸­ `targets` æ˜¯ 80 ç»´ one-hot å‘é‡
- æ”¹é€ åï¼š`targets` æ˜¯æ ‡é‡ 0/1ï¼ˆå‰æ™¯ or èƒŒæ™¯ï¼‰ï¼Œæ— éœ€ç±»åˆ«æ ‡ç­¾

### 6.3 Soft Count Lossï¼ˆè®¡æ•°æŸå¤±ï¼Œæ–°å¢ï¼‰

**æ ¸å¿ƒæ€æƒ³**ï¼šå°†æ‰€æœ‰ query çš„ sigmoid åˆ†æ•°æ±‚å’Œï¼Œä½œä¸ºæ¨¡å‹çš„"è½¯è®¡æ•°"é¢„æµ‹å€¼ï¼Œä¸ GT ç›®æ ‡æ•°é‡åš L1 æŸå¤±ã€‚

```python
def loss_count(self, outputs, targets, indices, num_boxes, **kwargs):
    Logits    = outputs["pred_logits"]              # [B, NQ, 1]
    SoftCount = torch.sigmoid(Logits).sum(dim=1).squeeze(-1)   # [B]

    GTCount = torch.tensor([t["count"] for t in targets],
                           dtype=torch.float32, device=device)

    return {"loss_count": F.l1_loss(SoftCount, GTCount)}
```

**ä¸ºä»€ä¹ˆä¸ç”¨ Hard Count**ï¼šHard Count éœ€è¦ä¸€ä¸ªé˜ˆå€¼ï¼ˆå¦‚ sigmoid > 0.5ï¼‰ï¼Œä½†è®­ç»ƒåˆæœŸæ‰€æœ‰ query çš„ sigmoid â‰ˆ 0.01ï¼ˆç”± bias åˆå§‹åŒ–å†³å®šï¼‰ï¼Œä»»ä½•æ­£æ•°é˜ˆå€¼éƒ½ä¼šè¿‡æ»¤æ‰æ‰€æœ‰é¢„æµ‹ã€‚Soft Count æ— éœ€é˜ˆå€¼ï¼Œä¿¡å·å§‹ç»ˆå¯ç”¨ã€‚

### 6.4 Top-K Soft Count Lossï¼ˆä¼˜åŒ–ç‰ˆï¼ŒåæœŸå¼•å…¥ï¼‰

**é—®é¢˜**ï¼šFocal Loss é¼“åŠ±æœªåŒ¹é… query çš„ sigmoid â†’ 0ï¼ˆèƒŒæ™¯ç±»å‹ä½ï¼‰ï¼Œè€ŒåŸºç¡€ Count Loss å¸Œæœ›æ‰€æœ‰ query çš„ sigmoid æ€»å’Œ â‰ˆ GT Countï¼ˆå¯èƒ½ > 100ï¼‰ï¼Œä¸¤è€…æ¢¯åº¦æ–¹å‘å†²çªã€‚

**è§£å†³æ–¹æ¡ˆ**ï¼šåªå¯¹å‰ K ä¸ªæœ€é«˜åˆ† query è®¡ç®— count lossï¼Œé¿å…ç›´æ¥è¦æ±‚èƒŒæ™¯ query è´¡çŒ®åˆ†æ•°ã€‚

```python
def loss_count_topk(self, outputs, targets, ...):
    Logits = outputs["pred_logits"].squeeze(-1)     # [B, NQ]
    Scores = torch.sigmoid(Logits)

    # åªå–å‰ K ä¸ªæœ€é«˜åˆ† queryï¼ˆK = min(count_topk_max, NQ)ï¼‰
    K = min(self.CountTopKMax, Scores.shape[1])     # é»˜è®¤ 200
    TopScores, _ = torch.topk(Scores, K, dim=1)
    SoftCount = TopScores.sum(dim=1)                # [B]

    GTCount = torch.tensor([t["count"] for t in targets], ...)
    return {"loss_count": F.l1_loss(SoftCount, GTCount)}
```

é€šè¿‡ `--count_topk` CLI å‚æ•°å¼€å…³ï¼Œ`--count_topk_max` æ§åˆ¶ K å€¼ã€‚

---

## 7. åŒˆç‰™åˆ© Matcher æ”¹é€ 

**æ–‡ä»¶**ï¼š`rfdetr/models/matcher.py`

**ä¿®æ”¹ç‚¹**ï¼šå°† `focal_alpha` å’Œ `focal_gamma` ä»ç¡¬ç¼–ç æ”¹ä¸ºå¯é…ç½®å‚æ•°ã€‚

```python
# æ”¹é€ å‰
class HungarianMatcher(nn.Module):
    def __init__(self, cost_class=2, cost_bbox=5, cost_giou=2):
        self.focal_alpha = 0.25   # ç¡¬ç¼–ç ï¼Œæ— æ³•å®éªŒè°ƒæ•´
        self.focal_gamma = 2.0

# æ”¹é€ å
class HungarianMatcher(nn.Module):
    def __init__(self, cost_class=2, cost_bbox=5, cost_giou=2,
                 focal_alpha=0.25, focal_gamma=2.0):
        self.focal_alpha = focal_alpha    # é€šè¿‡ CLI ä¼ å…¥
        self.focal_gamma = focal_gamma
```

é€šè¿‡ `TrainFscd.py` çš„ `--matcher_focal_alpha` å’Œ `--matcher_focal_gamma` å‚æ•°æ§åˆ¶ã€‚

**è°ƒæ•´è¿™ä¸¤ä¸ªå‚æ•°çš„æ„ä¹‰**ï¼š
- `focal_alpha`ï¼šæ§åˆ¶å‰æ™¯/èƒŒæ™¯æ ·æœ¬çš„ç›¸å¯¹æƒé‡ã€‚FSCD åœºæ™¯ä¸­ç›®æ ‡å¯†åº¦å˜åŒ–å¤§ï¼ˆGT count ä»ä¸ªä½æ•°åˆ°åƒä»¥ä¸Šï¼‰ï¼Œå¯èƒ½éœ€è¦ä¸åŒäº COCO çš„ Î± å€¼
- `focal_gamma`ï¼šæ§åˆ¶éš¾æ˜“æ ·æœ¬çš„å…³æ³¨ç¨‹åº¦ã€‚Î³ è¶Šå¤§ï¼Œæ¨¡å‹è¶Šä¸“æ³¨äºéš¾åˆ†æ ·æœ¬

---

## 8. æ•°æ®é›†åŠ è½½å™¨ï¼šFscd147Dataset

**æ–‡ä»¶**ï¼š`rfdetr/datasets/Fscd147.py`

### 8.1 æ•°æ®è§£ææµç¨‹

```python
def __getitem__(self, Idx):
    FileName = self.FileList[Idx]
    Ann      = self.Annotations[FileName]

    # --- 1. å›¾åƒåŠ è½½ï¼ˆæ”¯æŒä¸­æ–‡è·¯å¾„ï¼‰---
    # ä½¿ç”¨ numpy + cv2.imdecode æ›¿ä»£ cv2.imreadï¼Œé¿å… Windows ä¸­æ–‡è·¯å¾„é—®é¢˜
    ImgPath = os.path.join(self.ImgDir, FileName)
    ImgArr  = np.fromfile(ImgPath, dtype=np.uint8)
    Img     = cv2.imdecode(ImgArr, cv2.IMREAD_COLOR)
    Img     = Image.fromarray(cv2.cvtColor(Img, cv2.COLOR_BGR2RGB))

    # --- 2. è§£æ exemplar boxes ---
    # åŸå§‹æ ¼å¼ï¼š4 ä¸ªè§’ç‚¹ [y, x]ï¼Œéœ€è½¬ä¸º xyxy
    RawCoords = Ann["box_examples_coordinates"][:self.NumExemplars]
    ExemplarBoxes = []
    for Coords in RawCoords:
        Ys = [p[0] for p in Coords]   # æ³¨æ„ï¼šåŸå§‹æ˜¯ [y, x] é¡ºåºï¼
        Xs = [p[1] for p in Coords]
        ExemplarBoxes.append([min(Xs), min(Ys), max(Xs), max(Ys)])  # xyxy

    # --- 3. è§£æç›®æ ‡ç‚¹ â†’ ä¼ªè¾¹ç•Œæ¡† ---
    # FSCD-147 åªæœ‰ç‚¹æ ‡æ³¨ï¼Œç”¨å›ºå®šå¤§å°ï¼ˆé»˜è®¤ Â±4 åƒç´ ï¼‰ç”Ÿæˆä¼ªæ¡†
    Points = Ann["points"]           # [[x, y], ...]
    Boxes  = []
    for x, y in Points:
        Boxes.append([x - 4, y - 4, x + 4, y + 4])   # 8Ã—8 åƒç´ ä¼ªæ¡†

    # --- 4. æ„å»º Target å­—å…¸ ---
    Target = {
        "boxes":          torch.tensor(Boxes, dtype=torch.float32),        # [N, 4]
        "labels":         torch.zeros(len(Boxes), dtype=torch.long),       # class-agnostic â†’ å…¨ 0
        "exemplar_boxes": torch.tensor(ExemplarBoxes, dtype=torch.float32),# [K, 4]
        "points":         torch.tensor(Points, dtype=torch.float32),       # [N, 2]
        "count":          torch.tensor(float(len(Points))),                # ç›®æ ‡æ•°é‡
        "image_id":       torch.tensor(self.GetCocoImageId(FileName)),
        "orig_size":      torch.tensor([Ann["H"], Ann["W"]]),
        "size":           torch.tensor([Ann["H"], Ann["W"]]),
    }

    # --- 5. åº”ç”¨æ•°æ®å¢å¼º/å˜æ¢ ---
    Img, Target = self.Transforms(Img, Target)

    return Img, Target
```

### 8.2 COCO image_id æ˜ å°„

val/test é›†éœ€è¦ä¸ `instances_val.json` ä¸­çš„ `image_id` ä¸€è‡´ï¼Œæ‰èƒ½æ­£ç¡®è®¡ç®— APï¼š

```python
def _BuildFilenameToCocoIdMap(self):
    """é¢„æ„å»º filename â†’ coco_image_id æ˜ å°„"""
    if self.InstancesJsonPath is None:
        return {}
    with open(self.InstancesJsonPath) as f:
        CocoData = json.load(f)
    return {img["file_name"]: img["id"] for img in CocoData["images"]}

def GetCocoApi(self):
    """è¿”å› pycocotools.coco.COCO å¯¹è±¡ï¼Œç”¨äº CocoEvaluator"""
    from pycocotools.coco import COCO
    return COCO(self.InstancesJsonPath)
```

### 8.3 è‡ªå®šä¹‰ collate_fn

åŸå§‹ `collate_fn` ä¸å¤„ç† `exemplar_boxes`ï¼Œéœ€è¦è‡ªå®šä¹‰ä»¥æ‰“åŒ…ä¸º `NestedTensor`ï¼š

```python
def FscdCollateFn(Batch):
    Imgs, Targets = zip(*Batch)
    Samples = NestedTensor.from_tensor_list(list(Imgs))
    # Targets ä¿æŒä¸º listï¼Œä¸åšé¢å¤– padding
    return Samples, list(Targets)
```

---

## 9. æ•°æ®å¢å¼ºæ”¹é€ 

### 9.1 é—®é¢˜æ ¹æº

åŸå§‹ `transforms.py` ä¸­çš„ `crop`ã€`hflip`ã€`SquareResize` åªå¤„ç† `target["boxes"]`ï¼Œä¸å¤„ç† `target["exemplar_boxes"]` å’Œ `target["points"]`ï¼Œå¯¼è‡´ï¼š

- éšæœºè£å‰ªåï¼š`exemplar_boxes` åæ ‡ä»æ˜¯åŸå›¾åæ ‡ï¼Œä¸è£å‰ªåçš„å›¾åƒä¸åŒæ­¥
- æ°´å¹³ç¿»è½¬åï¼š`exemplar_boxes` ä¸ç¿»è½¬ï¼Œä½ç½®é”™è¯¯
- Resize åï¼š`exemplar_boxes` ä¸ç¼©æ”¾ï¼Œåæ ‡åç§»

### 9.2 `crop` å‡½æ•°ä¿®å¤

```python
def crop(image, target, region):
    i, j, h, w = region  # top, left, height, width
    image = F.crop(image, i, j, h, w)

    # ...ï¼ˆåŸæœ‰ boxes å¤„ç†é€»è¾‘ï¼‰...

    # ===== æ–°å¢ï¼šå¤„ç† exemplar_boxes =====
    if "exemplar_boxes" in target:
        eb = target["exemplar_boxes"].clone()       # [K, 4] xyxy
        eb -= torch.as_tensor([j, i, j, i])         # å¹³ç§»åæ ‡ç³»
        eb[:, 0::2].clamp_(0, w)                    # x åæ ‡è£å‰ª
        eb[:, 1::2].clamp_(0, h)                    # y åæ ‡è£å‰ª

        # é€€åŒ–ä¿æŠ¤ï¼šå¦‚æœ exemplar è¢«è£åˆ°é¢ç§¯ä¸º 0ï¼Œä¿ç•™åŸå§‹åæ ‡å¹¶æˆªæ–­
        Valid = ((eb[:,2]-eb[:,0]) > 1) & ((eb[:,3]-eb[:,1]) > 1)
        target["exemplar_boxes"] = eb[Valid] if Valid.any() else eb.clamp(min=0)

    # ===== æ–°å¢ï¼šå¤„ç† points =====
    if "points" in target:
        pts = target["points"].clone()              # [N, 2] xy
        pts -= torch.as_tensor([j, i])
        Keep = (pts[:,0] >= 0) & (pts[:,0] < w) & \
               (pts[:,1] >= 0) & (pts[:,1] < h)
        target["points"] = pts[Keep].clamp(min=0)
        target["count"]  = torch.tensor(float(Keep.sum()))

    # ===== ä¿®å¤ï¼šåªè¿‡æ»¤ target ä¸­å®é™…å­˜åœ¨çš„å­—æ®µ =====
    # åŸå§‹ä»£ç æ— æ¡ä»¶è®¿é—® target["iscrowd"]ï¼Œä½† FSCD target æ²¡æœ‰æ­¤å­—æ®µ
    for field in ["labels", "area", "iscrowd"]:
        if field in target:
            target[field] = target[field][keep]

    return image, target
```

### 9.3 `hflip` å‡½æ•°ä¿®å¤

```python
def hflip(image, target):
    W, H = image.size
    flipped_image = F.hflip(image)

    # ...ï¼ˆåŸæœ‰ boxes ç¿»è½¬é€»è¾‘ï¼‰...

    # ===== æ–°å¢ï¼šç¿»è½¬ exemplar_boxes =====
    if "exemplar_boxes" in target:
        eb = target["exemplar_boxes"]               # [K, 4] xyxy: (x1,y1,x2,y2)
        # ç¿»è½¬ï¼šx_new = W - x_oldï¼ŒåŒæ—¶äº¤æ¢ x1 å’Œ x2
        eb = torch.stack([W - eb[:,2], eb[:,1],
                          W - eb[:,0], eb[:,3]], dim=1)
        target["exemplar_boxes"] = eb

    # ===== æ–°å¢ï¼šç¿»è½¬ points =====
    if "points" in target:
        pts = target["points"].clone()
        pts[:,0] = W - pts[:,0]
        target["points"] = pts

    return flipped_image, target
```

### 9.4 `SquareResize` ä¿®å¤

```python
class SquareResize:
    def __init__(self, size):
        self.size = size

    def __call__(self, img, target):
        W, H = img.size
        img = F.resize(img, (self.size, self.size))

        # ...ï¼ˆåŸæœ‰ boxes ç¼©æ”¾é€»è¾‘ï¼‰...

        # ===== æ–°å¢ï¼šç¼©æ”¾ exemplar_boxes =====
        if "exemplar_boxes" in target:
            eb = target["exemplar_boxes"]
            ScaleX = self.size / W
            ScaleY = self.size / H
            Scale  = torch.tensor([ScaleX, ScaleY, ScaleX, ScaleY])
            target["exemplar_boxes"] = eb * Scale

        # ===== æ–°å¢ï¼šç¼©æ”¾ points =====
        if "points" in target:
            pts = target["points"]
            target["points"] = pts * torch.tensor([self.size / W, self.size / H])

        target["size"] = torch.tensor([self.size, self.size])
        return img, target
```

**ä¸ºä»€ä¹ˆç”¨ `SquareResize` è€Œé `RandomResize`**ï¼šä½¿ç”¨ `RandomResize([560], max_size=1120)` æ—¶ï¼Œå›¾åƒå¯èƒ½å˜ä¸º `560Ã—1066`ï¼Œä¸èƒ½è¢« DINOv2 Backbone çš„ `block_size=56` æ•´é™¤ï¼Œè§¦å‘æ–­è¨€é”™è¯¯ã€‚`SquareResize(560)` å¼ºåˆ¶è¾“å‡ºä¸º `560Ã—560`ï¼Œç¡®ä¿æ•´é™¤æ€§ã€‚

### 9.5 æ–°å¢ `PhotometricDistort` ç±»

```python
class PhotometricDistort:
    """åƒç´ çº§é¢œï¿½ï¿½ï¿½æ‰°åŠ¨ï¼Œä¸å½±å“ä»»ä½•åæ ‡æ ‡æ³¨"""
    def __init__(self):
        self.Distort = T.ColorJitter(
            brightness=0.4,
            contrast=0.4,
            saturation=0.4,
            hue=0.1
        )

    def __call__(self, img, target):
        if random.random() > 0.5:      # 50% æ¦‚ç‡åº”ç”¨
            img = self.Distort(img)
        return img, target             # target å®Œå…¨ä¸å˜
```

### 9.6 è®­ç»ƒå¢å¼ºæµæ°´çº¿

```python
def MakeFscdTransforms(Split, Resolution=560):
    if Split == "train":
        return T.Compose([
            T.RandomHorizontalFlip(p=0.5),           # éšæœºæ°´å¹³ç¿»è½¬
            PhotometricDistort(),                      # é¢œè‰²æ‰°åŠ¨ï¼ˆæ–°å¢ï¼‰
            T.RandomSelect(
                T.SquareResize(Resolution),            # ç›´æ¥ resize åˆ°æ–¹å½¢
                T.Compose([
                    T.RandomSizeCrop(                  # éšæœºè£å‰ªï¼ˆæ–°å¢ï¼‰
                        min_size=int(Resolution * 0.6),
                        max_size=Resolution
                    ),
                    T.SquareResize(Resolution),        # è£å‰ªå resize
                ]),
                p=0.5                                  # 50% æ¦‚ç‡éšæœºè£å‰ª
            ),
            T.ToTensor(),
            T.Normalize([0.485, 0.456, 0.406],
                        [0.229, 0.224, 0.225]),
        ])
    else:   # val / testï¼šæ— å¢å¼ºï¼Œç›´æ¥ resize
        return T.Compose([
            T.SquareResize(Resolution),
            T.ToTensor(),
            T.Normalize([0.485, 0.456, 0.406],
                        [0.229, 0.224, 0.225]),
        ])
```

---

## 10. è®­ç»ƒæµç¨‹è®¾è®¡

### 10.1 è®­ç»ƒè„šæœ¬ CLI å‚æ•°ï¼ˆ`TrainFscd.py`ï¼‰

```
åŸºç¡€å‚æ•°ï¼š
  --dataset_dir       FSCD-147 æ•°æ®é›†æ ¹ç›®å½•ï¼ˆå¿…é¡»ï¼‰
  --output_dir        è¾“å‡ºç›®å½•ï¼ˆé»˜è®¤ output_fscdï¼‰
  --model_size        base æˆ– largeï¼ˆé»˜è®¤ baseï¼‰
  --resume            ä» checkpoint æ–‡ä»¶æ¢å¤è®­ç»ƒ

è®­ç»ƒè¶…å‚æ•°ï¼š
  --epochs            è®­ç»ƒè½®æ•°ï¼ˆé»˜è®¤ 50ï¼‰
  --batch_size        æ‰¹å¤§å°ï¼ˆé»˜è®¤ 4ï¼‰
  --grad_accum_steps  æ¢¯åº¦ç´¯ç§¯æ­¥æ•°ï¼ˆé»˜è®¤ 1ï¼‰
  --lr                ä¸»å­¦ä¹ ç‡ï¼ˆé»˜è®¤ 5e-5ï¼‰
  --lr_encoder        Backbone å­¦ä¹ ç‡ï¼ˆé»˜è®¤ 1e-5ï¼‰
  --warmup_epochs     Warmup è½®æ•°ï¼ˆé»˜è®¤ 3ï¼‰
  --clip_max_norm     æ¢¯åº¦è£å‰ªé˜ˆå€¼ï¼ˆé»˜è®¤ 0.1ï¼‰
  --amp               å¯ç”¨æ··åˆç²¾åº¦ï¼ˆAMPï¼‰ï¼ˆé»˜è®¤ Trueï¼‰

æ¨¡å‹å‚æ•°ï¼š
  --prior_prob        åˆ†ç±»å¤´ bias åˆå§‹åŒ–å…ˆéªŒæ¦‚ç‡ï¼ˆé»˜è®¤ 0.01ï¼‰
  --num_exemplars     ä½¿ç”¨çš„ exemplar æ•°é‡ï¼ˆé»˜è®¤ 3ï¼‰

æŸå¤±å‚æ•°ï¼š
  --count_loss_coef   Count Loss æƒé‡ï¼ˆé»˜è®¤ 3.0ï¼‰
  --cls_loss_coef     åˆ†ç±» Loss æƒé‡ï¼ˆé»˜è®¤ 2ï¼‰
  --count_topk        æ˜¯å¦ä½¿ç”¨ Top-K Count Lossï¼ˆå¼€å…³ï¼‰
  --count_topk_max    Top-K Count Loss çš„ K å€¼ï¼ˆé»˜è®¤ 200ï¼‰

Matcher å‚æ•°ï¼š
  --matcher_focal_alpha   Matcher focal alphaï¼ˆé»˜è®¤ 0.25ï¼‰
  --matcher_focal_gamma   Matcher focal gammaï¼ˆé»˜è®¤ 2.0ï¼‰

é˜ˆå€¼å‚æ•°ï¼ˆè‡ªåŠ¨æ‰«æï¼‰ï¼š
  --threshold_min     é˜ˆå€¼æœç´¢ä¸‹é™ï¼ˆé»˜è®¤ 0.05ï¼‰
  --threshold_max     é˜ˆå€¼æœç´¢ä¸Šé™ï¼ˆé»˜è®¤ 0.60ï¼Œåˆå§‹ç‰ˆæœ¬ä¸º 0.30ï¼‰
  --threshold_steps   æœç´¢æ­¥æ•°ï¼ˆé»˜è®¤ 12ï¼‰

EMA å‚æ•°ï¼š
  --use_ema           å¯ç”¨ EMAï¼ˆé»˜è®¤ Trueï¼‰
  --ema_decay         EMA è¡°å‡ç‡ï¼ˆé»˜è®¤ 0.9998ï¼‰
```

### 10.2 ä¸‰ç»„å‚æ•°å­¦ä¹ ç‡ç­–ç•¥

```python
ParamGroups = [
    # ç»„ 1ï¼šBackboneï¼ˆDINOv2ï¼‰â€”â€” æå° lrï¼Œä¿æŠ¤é¢„è®­ç»ƒç‰¹å¾
    {
        "params": [p for n, p in Model.named_parameters()
                   if n.startswith("Backbone.") and p.requires_grad],
        "lr":           Args.lr_encoder,           # é»˜è®¤ 1e-5
        "weight_decay": 1e-4,
    },
    # ç»„ 2ï¼šDecoder â€”â€” ä¸­ç­‰ lr
    {
        "params": [p for n, p in Model.named_parameters()
                   if "TransformerModule." in n and "decoder" in n
                   and p.requires_grad],
        "lr":           Args.lr * lr_component_decay,  # é»˜è®¤ ~5e-5
        "weight_decay": 1e-4,
    },
    # ç»„ 3ï¼šå…¶ä»–ï¼ˆFSCD æ–°å¢æ¨¡å— + Projector + æ£€æµ‹å¤´ï¼‰â€”â€” ä¸» lr
    {
        "params": [p for n, p in Model.named_parameters()
                   if not n.startswith("Backbone.")
                   and not ("TransformerModule." in n and "decoder" in n)
                   and p.requires_grad],
        "lr":           Args.lr,                   # é»˜è®¤ 5e-5
        "weight_decay": 1e-4,
    },
]
```

### 10.3 å­¦ä¹ ç‡è°ƒåº¦ï¼šWarmup + Cosine Decay

```python
def LrLambda(Step: int) -> float:
    if Step < WarmupSteps:
        # çº¿æ€§ Warmupï¼ˆ0 â†’ 1ï¼‰
        return float(Step) / float(max(1, WarmupSteps))
    # Cosine è¡°å‡ï¼ˆ1 â†’ MinFactorï¼‰
    Progress   = (Step - WarmupSteps) / max(1, TotalSteps - WarmupSteps)
    MinFactor  = 0.01   # æœ€ç»ˆ lr = peak_lr Ã— 0.01
    return MinFactor + (1 - MinFactor) * 0.5 * (1 + math.cos(math.pi * Progress))

Scheduler = LambdaLR(Optimizer, LrLambda)
```

å¯è§†åŒ–ï¼ˆé»˜è®¤ 50 epochï¼Œwarmup=3ï¼‰ï¼š

```
lr
 â”‚   /â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾\
 â”‚  /                        \
 â”‚ /                           \
 â”‚/                              â€¾â€¾â€¾__
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ epoch
   0   3                         47  50
       warmup      cosine decay
```

### 10.4 EMAï¼ˆExponential Moving Averageï¼‰

```python
# åˆå§‹åŒ–
EmaModel = ModelEma(Model, decay=0.9998)

# æ¯ä¸ª batch ç»“æŸåæ›´æ–°
EmaModel.update(Model)

# éªŒè¯/æµ‹è¯•æ—¶ä½¿ç”¨ EMA æƒé‡ï¼ˆé€šå¸¸æ¯”å³æ—¶æƒé‡æ›´ç¨³å®šï¼‰
with torch.no_grad():
    EmaModel.ema.eval()
    ValStats = FscdEvaluate(EmaModel.ema, ...)
```

### 10.5 Checkpoint ä¿å­˜ç­–ç•¥

```python
# æ¯ä¸ª epoch æœ«å°¾ä¿å­˜ï¼ˆå®Œæ•´çŠ¶æ€ï¼Œç”¨äºæ–­ç‚¹ç»­è®­ï¼‰
SaveCheckpoint({
    "model":           Model.state_dict(),
    "ema_state_dict":  EmaModel.ema.state_dict(),   # EMA æƒé‡
    "ema_updates":     EmaModel.updates,
    "optimizer":       Optimizer.state_dict(),
    "lr_scheduler":    Scheduler.state_dict(),
    "epoch":           Epoch,
    "best_mae":        BestMae,
    "best_threshold":  BestThreshold,
}, OutputDir / "checkpoint.pth")

# å½“éªŒè¯ MAE åˆ›æ–°ä½æ—¶ï¼Œé¢å¤–ä¿å­˜ best checkpoint
if ValMae < BestMae:
    SaveCheckpoint({
        "model": EmaModel.ema.state_dict(),
        "epoch": Epoch,
    }, OutputDir / "checkpoint_best.pth")

# æ¯ 5 ä¸ª epoch å½’æ¡£ä¸€æ¬¡
if (Epoch + 1) % 5 == 0:
    SaveCheckpoint(..., OutputDir / f"checkpoint{Epoch:04d}.pth")
```

**æ–‡ä»¶å¤§å°å·®å¼‚**ï¼š
- `checkpoint.pth`ï¼šåŒ…å«ä¼˜åŒ–å™¨ã€è°ƒåº¦å™¨ã€EMA ç­‰å®Œæ•´çŠ¶æ€ï¼Œ**ä½“ç§¯å¤§**ï¼ˆæ•°ç™¾ MBï¼‰
- `checkpoint_best.pth`ï¼šåªå«æ¨¡å‹æƒé‡ï¼Œ**ä½“ç§¯å°**ï¼ˆçº¦ 130MB for Baseï¼‰

---

## 11. è¯„ä¼°æŒ‡æ ‡ä½“ç³»

### 11.1 æŒ‡æ ‡è¯´æ˜

| æŒ‡æ ‡ | è®¡ç®—æ–¹å¼ | è¯´æ˜ |
|------|---------|------|
| **MAE (soft)** | `mean(|sigmoid_sum - GT_count|)` | **ä¸»è¯„ä¼°æŒ‡æ ‡**ï¼Œæ— éœ€é˜ˆå€¼ï¼Œå§‹ç»ˆæœ‰æ•ˆ |
| **RMSE (soft)** | `sqrt(mean((sigmoid_sum - GT_count)Â²))` | å¯¹å¤§è¯¯å·®æ›´æ•æ„Ÿ |
| **MAE (hard)** | `mean(|(score > threshold).sum - GT_count|)` | ä½¿ç”¨éªŒè¯é›†æœ€ä¼˜é˜ˆå€¼ |
| **Best Threshold** | åœ¨éªŒè¯é›†ä¸Šæœç´¢ [threshold_min, threshold_max] | æ¯ä¸ª epoch è‡ªåŠ¨æ›´æ–° |
| **AP** | COCO mAP@[0.50:0.95] | æ ‡å‡†æ£€æµ‹ç²¾åº¦ |
| **AP50** | COCO AP@IoU=0.50 | å®½æ¾æ£€æµ‹ç²¾åº¦ |
| **Avg Soft Count** | æ‰€æœ‰å›¾çš„ soft count å‡å€¼ | å¯¹æ¯” GT å‡å€¼ï¼Œåˆ¤æ–­æ¬ /è¶…è®¡æ•° |
| **Avg Hard Count** | è¶…è¿‡é˜ˆå€¼çš„æ¡†æ•°å‡å€¼ | è¾…åŠ©å‚è€ƒ |
| **Matched Queries/Img** | åŒˆç‰™åˆ©åŒ¹é…åæ¯å¼ å›¾å®é™…åŒ¹é…çš„ query æ•° | è°ƒè¯•åŒ¹é…è´¨é‡ |

### 11.2 é˜ˆå€¼è‡ªåŠ¨æ‰«æï¼ˆ`ScanThreshold`ï¼‰

å–ä»£å›ºå®šé˜ˆå€¼ï¼Œåœ¨éªŒè¯é›†ä¸Šæœç´¢æœ€ä¼˜æ£€æµ‹é˜ˆå€¼ï¼š

```python
def ScanThreshold(AllLogits, AllGtCounts,
                  ThMin=0.05, ThMax=0.60, Steps=12):
    """åœ¨éªŒè¯é›†ä¸Šæœç´¢ä½¿ hard MAE æœ€å°çš„é˜ˆå€¼"""
    Candidates = torch.linspace(ThMin, ThMax, Steps)
    BestTh, BestMae = 0.1, float("inf")

    for Th in Candidates:
        # å¯¹æ‰€æœ‰éªŒè¯å›¾è®¡ç®— hard count
        HardCounts = [(torch.sigmoid(L) > Th).sum().float()
                      for L in AllLogits]
        Mae = F.l1_loss(torch.stack(HardCounts),
                        torch.stack(AllGtCounts)).item()
        if Mae < BestMae:
            BestMae, BestTh = Mae, Th.item()

    return BestTh, BestMae
```

**ä¸ºä»€ä¹ˆéœ€è¦æ­¤åŠŸèƒ½**ï¼šè®­ç»ƒåˆæœŸ sigmoid è¾“å‡ºå…¨éƒ¨ â‰ˆ 0.01ï¼Œä»»ä½•å›ºå®šé˜ˆå€¼ï¼ˆå¦‚ 0.3/0.5ï¼‰éƒ½ä¼šè¿‡æ»¤æ‰æ‰€æœ‰é¢„æµ‹ï¼Œå¯¼è‡´ hard MAE = GT å‡å€¼ï¼ˆâ‰ˆ63.8ï¼‰ï¼Œæ— æ³•è§‚å¯Ÿæ¨¡å‹æ˜¯å¦åœ¨è¿›æ­¥ã€‚è‡ªåŠ¨æ‰«æå¯ä»¥æ‰¾åˆ°èƒ½åæ˜ çœŸå®æ€§èƒ½çš„æœ€ä½é˜ˆå€¼ã€‚

### 11.3 matched_queries_per_image çš„ GroupDETR å½’ä¸€åŒ–

Group DETR è®­ç»ƒæ—¶ query æ•° = `300 Ã— 13 = 3900`ï¼ŒåŒ¹é…å™¨è¿”å›çš„æ˜¯ 3900 ä¸ª query ä¸­åŒ¹é…åˆ° GT çš„æ•°é‡ã€‚éœ€é™¤ä»¥ `group_detr` æ‰èƒ½å¾—åˆ°æ¯å¼ å›¾å®é™…åŒ¹é…çš„ query æ•°ï¼ˆå¯¹åº”æ¨ç†æ—¶çš„ 300 ä¸ª queryï¼‰ã€‚

```python
# ä¿®å¤å‰ï¼ˆé”™è¯¯ï¼‰ï¼šæ˜¾ç¤ºå€¼çº¦ä¸º 500+ï¼Œä¸åˆç†
MatchedPerImg = sum(len(s) for s, _ in indices) / BatchSize

# ä¿®å¤åï¼ˆæ­£ç¡®ï¼‰ï¼šå½’ä¸€åŒ–åˆ°å•å¼ å›¾çš„å®é™…åŒ¹é…æ•°
MatchedPerImg = sum(len(s) for s, _ in indices) / BatchSize / self.GroupDetr
```

---

## 12. é…ç½®ç³»ç»Ÿæ”¹é€ 

**æ–‡ä»¶**ï¼š`rfdetr/config.py`

### 12.1 RFDETRFSCDConfigï¼ˆBase ç‰ˆæœ¬ï¼‰

```python
@dataclass
class RFDETRFSCDConfig(RFDETRBaseConfig):
    num_classes:       int   = 1        # class-agnostic â†’ 1 ç±»
    num_queries:       int   = 300      # å¿…é¡»ä¸ rf-detr-base.pth ä¸€è‡´ï¼
    num_select:        int   = 300      # å¿…é¡»ä¸ rf-detr-base.pth ä¸€è‡´ï¼
    pretrain_weights:  str   = "rf-detr-base.pth"
    # FSCD ä¸“ç”¨å‚æ•°
    prior_prob:        float = 0.01
    num_exemplars:     int   = 3
    prototype_dim:     int   = 256
    exemplar_pool_size:int   = 7
```

> âš ï¸ `num_queries` å’Œ `num_select` åˆå§‹è¢«è¯¯è®¾ä¸º 500ï¼Œå¯¼è‡´ä¸é¢„è®­ç»ƒæƒé‡çš„ `RefpointEmbed.weight`ï¼ˆshape `[3900, 4]`ï¼‰ä¸åŒ¹é…ï¼ˆå˜ä¸º `[6500, 4]`ï¼‰ï¼Œå¼•å‘ `RuntimeError: size mismatch`ã€‚æ”¹å› 300 åè§£å†³ã€‚

### 12.2 RFDETRFSCDLargeConfigï¼ˆLarge ç‰ˆæœ¬ï¼‰

```python
@dataclass
class RFDETRFSCDLargeConfig(RFDETRLargeConfig):
    num_classes:       int   = 1
    pretrain_weights:  str   = "rf-detr-large.pth"
    prior_prob:        float = 0.01
    num_exemplars:     int   = 3
    prototype_dim:     int   = 384   # è·Ÿéš Large çš„ hidden_dim=384
    exemplar_pool_size:int   = 7
```

Large ç‰ˆæœ¬æ— éœ€ä¿®æ”¹æ¨¡å‹ï¿½ï¿½ï¿½ç ï¼Œå› ä¸º `FscdLWDETR` çš„æ‰€æœ‰ç»´åº¦éƒ½ä» `TransformerModule.d_model`ï¼ˆå³ `hidden_dim`ï¼‰åŠ¨æ€è·å–ã€‚

### 12.3 FSCDTrainConfig

```python
@dataclass
class FSCDTrainConfig(TrainConfig):
    dataset_file:          str   = "fscd147"
    count_loss_coef:       float = 3.0       # åˆå§‹ 0.5 â†’ 3.0ï¼ˆè°ƒå‚å†ç¨‹ä¸­æå‡ï¼‰
    cls_loss_coef:         float = 2.0
    bbox_loss_coef:        float = 5.0
    giou_loss_coef:        float = 2.0
    count_topk:            bool  = False
    count_topk_max:        int   = 200
    threshold_min:         float = 0.05
    threshold_max:         float = 0.60      # åˆå§‹ 0.30 â†’ 0.60
    threshold_steps:       int   = 12
    matcher_focal_alpha:   float = 0.25
    matcher_focal_gamma:   float = 2.0
```

---

## 13. æƒé‡åŠ è½½ç­–ç•¥

**æ–‡ä»¶**ï¼š`rfdetr/FscdMain.py`ï¼Œç±» `FscdModel`

### 13.1 åŠ è½½é€»è¾‘

```python
def _LoadPretrainWeights(self, WeightPath):
    """ä» rf-detr-base.pth æˆ– rf-detr-large.pth åŠ è½½é¢„è®­ç»ƒæƒé‡"""
    Ckpt = torch.load(WeightPath, map_location="cpu")
    StateDict = Ckpt.get("model", Ckpt)

    NewStateDict = {}
    for k, v in StateDict.items():
        if "class_embed" in k:
            # class_embed åŸæœ¬æ˜¯ [num_classes, hidden_dim] æˆ– [hidden_dim, num_classes]
            # åªå–ç¬¬ä¸€è¡Œï¼ˆå¯¹åº” class 0ï¼‰ï¼Œæ˜ å°„åˆ° ObjectnessEmbed
            new_k = k.replace("class_embed", "ObjectnessEmbed")
            NewStateDict[new_k] = v[:1] if v.dim() > 1 else v[:1]
        else:
            NewStateDict[k] = v

    # strict=Falseï¼šè·³è¿‡ size mismatch çš„ key
    # FSCD æ–°å¢æ¨¡å—ï¼ˆExemplarExtractor ç­‰ï¼‰çš„ key åœ¨ checkpoint ä¸­ä¸å­˜åœ¨ â†’ Missing keysï¼ˆæ­£å¸¸ï¼‰
    # ObjectnessEmbed ä¸åŸ class_embed ç»´åº¦ä¸åŒ â†’ strict=False å¤„ç†
    Missing, Unexpected = self.Model.load_state_dict(NewStateDict, strict=False)
```

### 13.2 å„æ¨¡å—çš„åˆå§‹åŒ–æ¥æº

| æ¨¡å— | åˆå§‹åŒ–æ–¹å¼ |
|------|-----------|
| `Backbone` | COCO é¢„è®­ç»ƒæƒé‡ï¼ˆå®Œæ•´è¿ç§»ï¼‰ |
| `Projector` | COCO é¢„è®­ç»ƒæƒé‡ï¼ˆå®Œæ•´è¿ç§»ï¼‰ |
| `TransformerModule`ï¼ˆå« decoderï¼‰ | COCO é¢„è®­ç»ƒæƒé‡ï¼ˆå®Œæ•´è¿ç§»ï¼‰ |
| `bbox_embed` | COCO é¢„è®­ç»ƒæƒé‡ï¼ˆå®Œæ•´è¿ç§»ï¼Œbbox å›å½’ä»»åŠ¡ç›¸åŒï¼‰ |
| `ObjectnessEmbed` | ä» `class_embed` ç¬¬ 0 è¡Œè¿ç§»ï¼Œbias ç”¨ `prior_prob` é‡æ–°åˆå§‹åŒ– |
| `ExemplarExtractor` | **éšæœºåˆå§‹åŒ–**ï¼ˆCOCO é¢„è®­ç»ƒä¸­æ— å¯¹åº”æ¨¡å—ï¼‰ |
| `ExemplarConditioning` | **éšæœºåˆå§‹åŒ–** |
| `ProtoProjection` | **éšæœºåˆå§‹åŒ–** |

---

## 14. æ¨ç†ä¸å·¥å…·è„šæœ¬

### 14.1 äº¤äº’å¼ Demoï¼ˆ`DemoFscd.py`ï¼‰

**ä½¿ç”¨æ–¹å¼**ï¼š

1. è¿è¡Œè„šæœ¬ï¼Œå¼¹å‡ºæ–‡ä»¶å¯¹è¯æ¡†é€‰æ‹©å›¾åƒ
2. å›¾åƒæ˜¾ç¤ºåœ¨ OpenCV çª—å£ä¸­
3. **é¼ æ ‡å·¦é”®æ‹–æ‹½**ç”»å‡º 1 ä¸ªï¼ˆæˆ–å¤šä¸ªï¼‰exemplar æ¡†
4. æŒ‰ `Enter` æˆ–ç©ºæ ¼é”®è§¦å‘æ¨ç†
5. ç»“æœæ˜¾ç¤ºï¼šæ©™è‰²æ¡†=æ£€æµ‹ç›®æ ‡ï¼Œé»„è‰²æ¡†=exemplarï¼Œå·¦ä¸Šè§’æ˜¾ç¤ºé¢„æµ‹è®¡æ•°

```bash
python DemoFscd.py --checkpoint output_fscd/checkpoint_best.pth
python DemoFscd.py --checkpoint output_fscd/checkpoint_best.pth --model_size large
```

**ä¸­æ–‡è·¯å¾„å…¼å®¹**ï¼šä½¿ç”¨ `numpy + cv2.imdecode` ä»£æ›¿ `cv2.imread`ï¼š

```python
ImgArr = np.fromfile(ImgPath, dtype=np.uint8)
Img    = cv2.imdecode(ImgArr, cv2.IMREAD_COLOR)
```

> æ³¨æ„ï¼šéœ€è¦å®‰è£… `opencv-contrib-python`ï¼ˆå¸¦ GUI æ”¯æŒï¼‰ï¼Œä¸èƒ½ä½¿ç”¨ `opencv-python-headless`ã€‚

### 14.2 Benchmark è¯„ä¼°ï¼ˆ`EvalFscd.py`ï¼‰

æ”¯æŒ FSCD-147 å’Œ FSCD-LVIS ä¸¤ä¸ªæ ‡å‡† Benchmarkï¼š

```bash
# FSCD-147 æµ‹è¯•é›†è¯„ä¼°
python EvalFscd.py \
  --checkpoint output_fscd/checkpoint_best.pth \
  --dataset fscd147 \
  --dataset_dir /path/to/FSCD147 \
  --split test

# FSCD-LVIS è¯„ä¼°ï¼ˆä¸‹è½½åå¯ç”¨ï¼‰
python EvalFscd.py \
  --checkpoint output_fscd/checkpoint_best.pth \
  --dataset fscd_lvis \
  --dataset_dir /path/to/FSCD_LVIS \
  --split test
```

è¾“å‡ºæŒ‡æ ‡ï¼šMAEã€RMSEã€NAEï¼ˆNormalized Absolute Errorï¼‰ã€SREï¼ˆSquared Relative Errorï¼‰ã€APã€AP50ã€‚

---

## 15. ç¯å¢ƒé…ç½®

### 15.1 ç¡¬ä»¶è¦æ±‚

| é…ç½® | Base æ¨¡å‹ | Large æ¨¡å‹ |
|------|----------|-----------|
| æœ€ä½ GPU æ˜¾å­˜ | 8GBï¼ˆbatch=2ï¼‰ | 16GBï¼ˆbatch=1ï¼‰ |
| æ¨è | RTX 4060+ | RTX 4090 / A100 |
| å®æµ‹ | RTX 4060 Laptop 8GBï¼Œbatch=2ï¼Œgrad_accum=2 | â€” |

### 15.2 å…³é”®ä¾èµ–ç‰ˆæœ¬

| åŒ… | ç‰ˆæœ¬ | å¤‡æ³¨ |
|----|------|------|
| Python | 3.10 / 3.12 | |
| PyTorch | 2.10.0+cu128 | éœ€ GPU ç‰ˆï¼Œé CPU ç‰ˆ |
| torchvision | 0.25.0+cu128 | |
| CUDA | 12.8 | |
| transformers | â‰¥ 4.44 | åŸ 4.39.3 ç¼ºå°‘ `torch_int`ï¼Œéœ€å‡çº§ |
| tqdm | 4.67.3 | è¿›åº¦æ¡ |
| opencv-contrib-python | æœ€æ–° | å¸¦ GUI ç‰ˆæœ¬ï¼Œæ›¿æ¢ headless |
| pycocotools | â€” | AP è¯„ä¼° |

### 15.3 `pyproject.toml` å…³é”®æ”¹åŠ¨

```toml
[tool.uv]
[[tool.uv.index]]
name     = "pytorch-cu128"
url      = "https://download.pytorch.org/whl/cu128"
explicit = true

[tool.uv.sources]
torch       = [{index = "pytorch-cu128"}]
torchvision = [{index = "pytorch-cu128"}]

[project.dependencies]
transformers = ">=4.44"
```

### 15.4 å¸¸ç”¨è®­ç»ƒå‘½ä»¤

```bash
# åŸºç¡€è®­ç»ƒï¼ˆä»å¤´å¼€å§‹ï¼‰
python TrainFscd.py --dataset_dir /path/to/FSCD147

# OOM å¤„ç†ï¼ˆå‡å° batch + æ¢¯åº¦ç´¯ç§¯ï¼‰
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True \
python TrainFscd.py --dataset_dir /path/to/FSCD147 \
  --batch_size 2 --grad_accum_steps 2

# æ–­ç‚¹ç»­è®­
python TrainFscd.py --dataset_dir /path/to/FSCD147 \
  --resume output_fscd/checkpoint.pth

# ä½¿ç”¨ Large æ¨¡å‹
python TrainFscd.py --dataset_dir /path/to/FSCD147 \
  --model_size large --batch_size 1 --grad_accum_steps 4

# å¼€å¯ Top-K Count Loss
python TrainFscd.py --dataset_dir /path/to/FSCD147 \
  --count_topk --count_topk_max 150 --count_loss_coef 3.0
```

---

## 16. ä¼˜åŒ–è°ƒå‚å†ç¨‹

### 16.1 é˜¶æ®µä¸€ï¼šåŸºç¡€å»ºè®¾ï¼ˆP0ï¼‰

**é—®é¢˜**ï¼šåˆå§‹è®­ç»ƒ 6 ä¸ª epoch å val_loss å®Œå…¨å¡æ­»åœ¨ ~128ï¼Œ`val_mean_pred_count` ä¸€ç›´çº¦ä¸º 4.0ï¼ˆGT å‡å€¼ 63.8 å·®è·æ‚¬æ®Šï¼‰ã€‚

**æ ¹å› åˆ†æ**ï¼š
1. æ— æ•°æ®å¢å¼º â†’ 3659 å¼ è®­ç»ƒå›¾ä¸¥é‡ï¿½ï¿½æ‹Ÿåˆ
2. `count_loss_coef=0.5` â†’ count loss åœ¨æ€» loss ä¸­å æ¯”ä»…çº¦ 3%ï¼Œä¿¡å·å¤ªå¼±
3. è¯„ä¼°ç”¨å›ºå®šé˜ˆå€¼ 0.5 â†’ è®­ç»ƒåˆæœŸæ‰€æœ‰ sigmoid â‰ˆ 0.01ï¼Œå…¨è¢«è¿‡æ»¤ â†’ `hard_count = 0` â†’ `MAE = GT_mean`ï¼Œçœ‹ä¸å‡ºä»»ä½•è¿›æ­¥

**ä¿®å¤**ï¼š
- åŠ å…¥æ•°æ®å¢å¼ºï¼ˆHFlip + ColorJitter + RandomSizeCropï¼‰
- `count_loss_coef`: 0.5 â†’ **3.0**
- è¯„ä¼°æ”¹ç”¨ Soft Countï¼ŒåŒæ—¶ä¿ç•™ Hard Count ä½œä¸ºå‚è€ƒ
- é˜ˆå€¼æ”¹ä¸ºè‡ªåŠ¨æ‰«æï¼ˆä¸å†å›ºå®š 0.5ï¼‰

### 16.2 é˜¶æ®µäºŒï¼šé˜ˆå€¼ä¸åˆ†ç±»ä¼˜åŒ–ï¼ˆP1ï¼‰

**é—®é¢˜**ï¼šåŠ äº†æ•°æ®å¢å¼ºå ema_rmse å¼€å§‹ç¼“æ…¢ä¸‹é™ï¼ˆ135 â†’ 133ï¼‰ï¼Œä½†æ ¸å¿ƒé—®é¢˜æœªè§£å†³ï¼Œval_pred_count ä»çº¦ 4.0ã€‚

**ä¿®å¤**ï¼š
- **é˜ˆå€¼ä¸Šé™æ‰©å¤§**ï¼š`threshold_max`: 0.30 â†’ **0.60**ï¼ˆä¹‹å‰æœç´¢èŒƒå›´å¤ªçª„ï¼Œæ‰¾åˆ°çš„"æœ€ä¼˜"é˜ˆå€¼ä»ç„¶è¿‡é«˜ï¼‰
- **prior_prob å¯é…ç½®**ï¼šå…è®¸å®éªŒ 0.01/0.03/0.05ï¼Œè§‚å¯Ÿå¯¹è®­ç»ƒåˆæœŸåˆ†æ•°åˆ†å¸ƒçš„å½±å“
- **ä¿®å¤ EMA resume**ï¼šresume æ—¶ä¸å†é‡ç½® EMA çŠ¶æ€ï¼Œé¿å… EMA æƒé‡æ±¡æŸ“

### 16.3 é˜¶æ®µä¸‰ï¼šæ¢¯åº¦ä¿¡å·å¼ºåŒ–ï¼ˆP2ï¼‰

**é—®é¢˜**ï¼šæ ¹æœ¬çŸ›ç›¾ â€”â€” Focal Loss ä¸ Count Loss æ¢¯åº¦å†²çªã€‚

**åˆ†æ**ï¼š
- 300 ä¸ª query ä¸­çº¦ 64 ä¸ªåŒ¹é…åˆ° GTï¼ˆå¯¹åº” GT count â‰ˆ 64ï¼‰
- Focal Loss çš„"å‹ä½èƒŒæ™¯"ä¿¡å·æ¥è‡ª **236 ä¸ªè´Ÿæ ·æœ¬**ï¼Œæ¢¯åº¦æ–¹å‘ï¼šsigmoid â†’ 0
- Count Loss çš„"æ‹‰é«˜æ€»å’Œ"ä¿¡å·å¸Œæœ›æ€»å’Œ â‰ˆ 64ï¼Œæ¢¯åº¦æ–¹å‘ï¼šsigmoid â†’ ç›¸å¯¹å¢å¤§
- 236 ä¸ªè´Ÿæ ·æœ¬çš„ Focal Loss ä¿¡å·è¿œå¼ºäº Count Lossï¼Œå¯¼è‡´ sigmoid å…¨éƒ¨è¢«å‹ä½

**ä¿®å¤**ï¼š
- **Matcher å‚æ•°å¯é…ç½®**ï¼šå…è®¸è°ƒæ•´ `focal_gamma`ï¼ˆé™ä½ gamma å¯å‡å¼±å¯¹éš¾è´Ÿæ ·æœ¬çš„å…³æ³¨ï¼‰
- **Top-K Count Loss**ï¼šåªå¯¹å‰ K ä¸ªæœ€é«˜åˆ† query è®¡ç®— count lossï¼Œé¿å…ç›´æ¥è¦æ±‚èƒŒæ™¯ query è´¡çŒ®åˆ†æ•°
- **`matched_queries_per_image` æ—¥å¿—**ï¼šå½’ä¸€åŒ–åå†™å…¥ logï¼Œæ–¹ä¾¿è§‚å¯ŸåŒ¹é…è´¨é‡

### 16.4 è¶…å‚æ•°æ¼”å˜æ—¶é—´çº¿

| å‚æ•° | åˆå§‹å€¼ | å½“å‰å€¼ | æ”¹åŠ¨åŸå›  |
|------|--------|--------|---------|
| `count_loss_coef` | 0.5 | **3.0** | count ä¿¡å·å¤ªå¼± |
| `threshold_max` | 0.30 | **0.60** | æœç´¢èŒƒå›´ä¸è¶³ï¼Œé—æ¼æœ‰æ•ˆé˜ˆå€¼ |
| `num_queries` | 500ï¼ˆè¯¯è®¾ï¼‰ | **300** | ä¸é¢„è®­ç»ƒæƒé‡ size mismatch |
| `num_select` | 500ï¼ˆè¯¯è®¾ï¼‰ | **300** | åŒä¸Š |
| `count_topk_max` | N/A | **200** | Top-K Count Loss æ–°å¢ |
| `threshold_min` | 0.1 | **0.05** | å…è®¸æ›´ä½é˜ˆå€¼ä»¥é€‚åº”è®­ç»ƒåˆæœŸ |

---

## 17. å®éªŒç»“æœè®°å½•

### 17.1 åˆå§‹è®­ç»ƒï¼ˆæ— å¢å¼ºï¼Œcount_coef=0.5ï¼‰

| Epoch | train_loss | val_mae(soft) | val_ap50 | val_pred_count |
|-------|-----------|--------------|---------|----------------|
| 0     | 61.9      | 60.2         | 0.22    | 3.6            |
| 6     | 24.5      | 59.6         | 0.06    | 4.0            |
| 49    | 8.75      | 59.79        | 0.05    | 4.0            |

**ç»“è®º**ï¼šepoch 6 å val å®Œå…¨åœæ»ï¼Œä¸¥é‡è¿‡æ‹Ÿåˆã€‚50 ä¸ª epoch è®­ç»ƒå val å‡ ä¹æ²¡æœ‰è¿›æ­¥ã€‚

### 17.2 P0 ä¿®å¤åï¼ˆåŠ å¢å¼º + count_coef=3.0ï¼Œå‰ 12 epochï¼‰

| Epoch | train_loss | val_mae(soft) | ema_val_rmse | ema_hard_count |
|-------|-----------|--------------|-------------|----------------|
| 0     | 58.3      | 59.4         | 137.3       | 0.0            |
| 6     | 26.8      | 59.8         | 134.5       | 0.0            |
| 11    | 24.1      | 59.67        | 133.1       | 0.04~0.1       |

**ç»“è®º**ï¼šema_rmse å¼€å§‹ç¼“æ…¢ä¸‹é™ï¼ˆ137 â†’ 133ï¼‰ï¼Œ`ema_hard_count` é¦–æ¬¡å‡ºç°éé›¶å€¼ï¼ˆä¹‹å‰ 50 epoch å…¨ä¸º 0ï¼‰ï¼Œè¯´æ˜æ•°æ®å¢å¼ºå¼€å§‹å‘æŒ¥ä½œç”¨ã€‚

### 17.3 ä¸‰ç»„å®éªŒå¯¹æ¯”ï¼ˆexpA/expB/expCï¼‰

| å®éªŒ | Best val_MAE | æ’å | å»ºè®® |
|------|-------------|------|------|
| **expA** | **~26.20** | ğŸ† ç¬¬ 1 | ä½œä¸ºä¸»çº¿ç»§ç»­ |
| expC | ~30.43 | ç¬¬ 2 | â€” |
| expB | ~30.52 | ç¬¬ 3 | â€” |

### 17.4 å·²å‘å¸ƒæƒé‡

- **è®­ç»ƒè½®æ•°**ï¼š10 ä¸ª Epochï¼ˆç®—åŠ›é™åˆ¶ï¼‰
- **ä¸‹è½½**ï¼š[ç™¾åº¦ç½‘ç›˜](https://pan.baidu.com/s/1qjRXuc6sIl0WlkLGKzSyiA?pwd=wfei)ï¼ˆæå–ç : wfeiï¼‰

---

## 18. å·²çŸ¥é—®é¢˜ä¸åç»­æ–¹å‘

### 18.1 å½“å‰æ ¸å¿ƒé—®é¢˜

| é—®é¢˜ | ä¸¥é‡ç¨‹åº¦ | è¯´æ˜ |
|------|---------|------|
| `val_pred_count â‰ˆ 4.0`ï¼ˆGT å‡å€¼ 63.8ï¼‰ | ğŸ”´ æ ¸å¿ƒ | FiLM conditioning å¯èƒ½æœªæœ‰æ•ˆæ³¨å…¥ exemplar ä¿¡æ¯ |
| Focal Loss vs Count Loss æ¢¯åº¦å†²çª | ğŸŸ¡ å·²éƒ¨åˆ†ç¼“è§£ | Top-K Count Loss ç¼“è§£ï¼Œä½†æœªæ ¹æœ¬è§£å†³ |
| EMA/resume çŠ¶æ€æ±¡æŸ“ï¼ˆå·²ä¿®å¤ï¼‰ | âœ… å·²ä¿®å¤ | â€” |
| FSCD-LVIS è¯„ä¼°æœªå®Œæˆ | ğŸŸ¡ å¾…å®Œæˆ | ç­‰å¾…æ•°æ®é›†ä¸‹è½½ |

### 18.2 P1 æ”¹è¿›ï¼ˆå¾…å®æ–½ï¼‰

**â‘  FiLM â†’ Residual å½¢å¼**
```python
# å½“å‰ç‰ˆæœ¬ï¼ˆåˆå§‹åŒ–æ—¶ Scale å¯èƒ½ç ´åé¢„è®­ç»ƒç‰¹å¾ï¼‰ï¼š
Output = Src * Scale + Shift

# æ”¹è¿›æ–¹æ¡ˆï¼ˆæ®‹å·®å½¢å¼ï¼Œåˆå§‹æ—¶ Scaleâ‰ˆ0ï¼Œä¸ç ´åç‰¹å¾ï¼‰ï¼š
Output = Src * (1 + Scale) + Shift
```

**â‘¡ Decoder æ¯å±‚æ³¨å…¥ exemplar**

å½“å‰åªåœ¨ Projector è¾“å‡ºï¼ˆEncoder ç«¯ï¼‰åšä¸€æ¬¡ FiLM æ¡ä»¶åŒ–ã€‚æ”¹è¿›ï¼šåœ¨ Decoder çš„æ¯ä¸€å±‚éƒ½æ³¨å…¥ Prototype ä¿¡æ¯ï¼ˆç±»ä¼¼ DAVEï¼‰ã€‚

**â‘¢ Backbone å­¦ä¹ ç‡æé«˜**

å½“å‰ `lr_encoder=1e-5` å‡ ä¹ç›¸å½“äºå†»ç»“ã€‚æé«˜åˆ° `5e-5` ä»¥è®© DINOv2 ç‰¹å¾æ›´å¥½åœ°é€‚åº” FSCD ä»»åŠ¡ã€‚

**â‘£ Cross-Attention Conditioning æ›¿ä»£ FiLM**

å°† `ExemplarConditioningModule` æ”¹ä¸ºçœŸæ­£çš„ Cross-Attentionï¼Œè®© image features ç›´æ¥ attend to exemplar featuresï¼Œæå–æ›´ç»†ç²’åº¦çš„ç›¸å…³æ€§ã€‚

### 18.3 é•¿æœŸæ–¹å‘

- [ ] ä¼˜åŒ–è¾¹ç•Œæ¡†æŸå¤±ï¼ˆå¼•å…¥ CIoU æˆ– DIoUï¼‰
- [ ] å¼•å…¥ NMS åå¤„ç†ï¼Œå‡å°‘å¯†é›†åœºæ™¯ä¸‹çš„é‡å é¢„æµ‹æ¡†
- [ ] æ”¯æŒ FSCD-LVIS æ•°æ®é›†ï¼ˆ377 ç±»ï¼‰
- [ ] å¯†åº¦å›¾ç›‘ç£ï¼ˆFSCD-147 æä¾›äº† density mapï¼‰
- [ ] ä¸¤é˜¶æ®µæ¨ç†ï¼ˆå‚è€ƒ DAVEï¼‰
- [ ] æ›´é•¿æ—¶é—´è®­ç»ƒï¼ˆå½“å‰æƒé‡ä»… 10 epochï¼‰

---

## 19. å…³é”® Bug è®°å½•

### Bug 1ï¼š`num_queries` é…ç½®é”™è¯¯å¯¼è‡´ size mismatch

| é¡¹ç›® | å†…å®¹ |
|------|------|
| **ç°è±¡** | `RuntimeError: size mismatch for RefpointEmbed.weight: shape [6500, 4] vs [3900, 4]` |
| **åŸå› ** | `RFDETRFSCDConfig` åˆå§‹è®¾ç½® `num_queries=500`ï¼Œè€Œé¢„è®­ç»ƒæƒé‡ç”¨ `num_queries=300`ã€‚è®­ç»ƒæ—¶ `500Ã—13=6500` vs é¢„è®­ç»ƒçš„ `300Ã—13=3900`ï¼Œä¸åŒ¹é…ã€‚ |
| **ä¿®å¤** | å°†é»˜è®¤å€¼æ”¹å› `num_queries=300, num_select=300`ï¼Œä¸ `rf-detr-base.pth` ä¿æŒä¸€è‡´ã€‚ |

### Bug 2ï¼šå›¾åƒå°ºå¯¸ä¸æ•´é™¤ `block_size`

| é¡¹ç›® | å†…å®¹ |
|------|------|
| **ç°è±¡** | `AssertionError: image size 560Ã—1066 not divisible by block_size=56` |
| **åŸå› ** | ä½¿ç”¨ `RandomResize([560], max_size=1120)` åï¼Œåªçº¦æŸçŸ­è¾¹ä¸º 560ï¼Œé•¿è¾¹å¯ä»¥åˆ° 1120ï¼Œä¸”ä¸ä¸€å®šï¿½ï¿½ï¿½é™¤ DINOv2 Backbone çš„ `block_size=56`ã€‚ |
| **ä¿®å¤** | æ”¹ç”¨ `SquareResize(560)`ï¼Œå¼ºåˆ¶è¾“å‡ºä¸º `560Ã—560` æ–¹å½¢ï¼Œç¡®ä¿æ•´é™¤æ€§ã€‚ |

### Bug 3ï¼štransforms ä¸åŒæ­¥ `exemplar_boxes`

| é¡¹ç›® | å†…å®¹ |
|------|------|
| **ç°è±¡** | åŠ å…¥ RandomSizeCrop åï¼Œexemplar box åæ ‡è½åœ¨è£å‰ªåŒºåŸŸä¹‹å¤–ï¼Œå¯¼è‡´ RoI Align æå–ç©ºç‰¹å¾ã€‚ |
| **åŸå› ** | `transforms.py` çš„ `crop`ã€`hflip`ã€`SquareResize` åªå¤„ç† `target["boxes"]`ï¼Œä¸å¤„ç† `target["exemplar_boxes"]` å’Œ `target["points"]`ã€‚ |
| **ä¿®å¤** | åœ¨ä¸Šè¿°ä¸‰ä¸ªå‡½æ•°ä¸­å‡æ·»åŠ å¯¹ `exemplar_boxes` å’Œ `points` çš„åŒæ­¥å˜æ¢é€»è¾‘ï¼ˆè§ç¬¬ 9 èŠ‚ï¼‰ã€‚ |

### Bug 4ï¼š`crop` å‡½æ•°è®¿é—®ä¸å­˜åœ¨çš„å­—æ®µ

| é¡¹ç›® | å†…å®¹ |
|------|------|
| **ç°è±¡** | è§¦å‘ RandomSizeCrop æ—¶æŠ¥ `KeyError: 'iscrowd'`ã€‚ |
| **åŸå› ** | `crop` å‡½æ•°ä¸­æ— æ¡ä»¶æ‰§è¡Œ `target["iscrowd"]`ï¼Œä½† FSCD-147 çš„ target å­—å…¸ä¸­æ²¡æœ‰æ­¤å­—æ®µï¼ˆè¿™æ˜¯ COCO ä¸“æœ‰å­—æ®µï¼‰ã€‚ |
| **ä¿®å¤** | æ”¹ä¸º `if field in target: target[field] = target[field][keep]`ã€‚ |

### Bug 5ï¼šEMA Resume çŠ¶æ€æ±¡æŸ“

| é¡¹ç›® | å†…å®¹ |
|------|------|
| **ç°è±¡** | Resume è®­ç»ƒå `ema_val_ap50` ä» 0.06 çªç„¶è·³åˆ° 0.36ï¼Œç„¶ååˆè¿…é€Ÿè¡°å‡ï¼Œè®­ç»ƒä¸ç¨³å®šã€‚ |
| **åŸå› ** | Resume æ—¶åªæ¢å¤äº† model æƒé‡ï¼ŒEMA ä»å½“å‰ï¼ˆresume åçš„ï¼‰model æƒé‡é‡æ–°åˆå§‹åŒ–ï¼Œå¯¼è‡´ EMA ä¸ä¹‹å‰ç§¯ç´¯çš„çŠ¶æ€ä¸è¿ç»­ã€‚ |
| **ä¿®å¤** | Checkpoint ä¸­ä¿å­˜ `ema_state_dict` å’Œ `ema_updates`ï¼ŒResume æ—¶å®Œæ•´æ¢å¤ã€‚ |

### Bug 6ï¼š`matched_queries_per_image` æ•°å€¼è™šé«˜

| é¡¹ç›® | å†…å®¹ |
|------|------|
| **ç°è±¡** | æ—¥å¿—ä¸­ `matched_queries_per_image > 500`ï¼Œä¸åˆç†ï¼ˆæ¯å¼ å›¾åªæœ‰å‡ åä¸ªç›®æ ‡ï¼‰ã€‚ |
| **åŸå› ** | Group DETR è®­ç»ƒæ—¶ query æ€»æ•° = `300 Ã— 13 = 3900`ï¼ŒåŒ¹é…ç»“æœæœªé™¤ä»¥ `group_detr=13`ã€‚ |
| **ä¿®å¤** | è®¡ç®—æ—¶é™¤ä»¥ `self.GroupDetr`ï¼Œå½’ä¸€åŒ–åˆ°å¯¹åº”æ¨ç†æ—¶ 300 ä¸ª query çš„å°ºåº¦ã€‚ |

---
*é¡¹ç›®ä»“åº“ï¼šhttps://github.com/Yes-buter/RF-DETR-FSCD*

